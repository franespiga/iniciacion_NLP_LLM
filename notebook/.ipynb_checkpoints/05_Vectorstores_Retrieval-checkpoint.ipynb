{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Vector Stores y Retrieval\n",
    "\n",
    "## Curso de LLMs y Aplicaciones de IA\n",
    "\n",
    "**Duración estimada:** 2-2.5 horas\n",
    "\n",
    "---\n",
    "\n",
    "## Índice\n",
    "\n",
    "1. [Introducción a Vector Stores](#intro)\n",
    "2. [FAISS: Vector Store local](#faiss)\n",
    "3. [Document Loaders](#loaders)\n",
    "4. [Text Splitters](#splitters)\n",
    "5. [Similarity Search](#search)\n",
    "6. [Persistencia y carga](#persistencia)\n",
    "7. [Ejercicios prácticos](#ejercicios)\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos de aprendizaje\n",
    "\n",
    "Al finalizar este notebook, serás capaz de:\n",
    "- Entender qué son los vector stores y cómo funcionan\n",
    "- Crear y usar FAISS para búsqueda vectorial\n",
    "- Cargar documentos desde diferentes fuentes\n",
    "- Dividir documentos en chunks óptimos\n",
    "- Realizar búsquedas semánticas eficientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"intro\"></a>\n",
    "## 1. Introducción a Vector Stores\n",
    "\n",
    "### ¿Qué es un Vector Store?\n",
    "\n",
    "Un **Vector Store** (base de datos vectorial) es un sistema diseñado para almacenar, indexar y buscar vectores de alta dimensionalidad de forma eficiente.\n",
    "\n",
    "### ¿Por qué son importantes?\n",
    "\n",
    "Los LLMs tienen conocimiento limitado a su fecha de entrenamiento y no conocen datos privados/corporativos. Los vector stores permiten:\n",
    "\n",
    "1. **Búsqueda semántica**: Encontrar documentos por significado, no keywords\n",
    "2. **Memoria a largo plazo**: Almacenar conocimiento externo\n",
    "3. **RAG**: Retrieval-Augmented Generation\n",
    "\n",
    "### Opciones populares\n",
    "\n",
    "| Vector Store | Tipo | Características |\n",
    "|--------------|------|----------------|\n",
    "| **FAISS** | Local | Gratuito, rápido, en memoria |\n",
    "| **Chroma** | Local | Gratuito, persistente, fácil de usar |\n",
    "| **Pinecone** | Cloud | Escalable, managed, pago |\n",
    "| **Weaviate** | Cloud/Local | Open source, GraphQL |\n",
    "| **Qdrant** | Cloud/Local | Open source, Rust |\n",
    "\n",
    "Para este curso usamos **FAISS** por ser gratuito y no requerir infraestructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 5.1.0 requires huggingface-hub<2.0,>=1.3.0, but you have huggingface-hub 0.36.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-huggingface 1.2.0 requires huggingface-hub<1.0.0,>=0.33.4, but you have huggingface-hub 1.4.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (all free)\n",
    "#%pip install -q langchain langchain-community langchain-huggingface\n",
    "#%pip install -q faiss-cpu sentence-transformers\n",
    "#%pip install -q beautifulsoup4 pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías instaladas ✓\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Librerías instaladas ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"faiss\"></a>\n",
    "## 2. FAISS: Vector Store local\n",
    "\n",
    "**FAISS** (Facebook AI Similarity Search) es una librería desarrollada por Meta para búsqueda eficiente de vectores similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo de embeddings (gratuito)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|█████████████████████████████████████████████████████████████████████| 103/103 [00:00<00:00, 982.47it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión del embedding: 384\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "#from langchain.docstore.document import Document\n",
    "from langchain_core.documents import Document\n",
    "# Load free embedding model\n",
    "print(\"Cargando modelo de embeddings (gratuito)...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Test embedding\n",
    "test_vector = embeddings.embed_query(\"Hello world\")\n",
    "print(f\"Dimensión del embedding: {len(test_vector)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creados 5 documentos\n"
     ]
    }
   ],
   "source": [
    "# Create simple documents\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Python es un lenguaje de programación interpretado y de alto nivel.\",\n",
    "        metadata={\"source\": \"python.txt\", \"topic\": \"programming\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"JavaScript es el lenguaje de la web, ejecutado en navegadores.\",\n",
    "        metadata={\"source\": \"javascript.txt\", \"topic\": \"programming\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Machine Learning es un subcampo de la inteligencia artificial.\",\n",
    "        metadata={\"source\": \"ml.txt\", \"topic\": \"AI\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Deep Learning usa redes neuronales con múltiples capas.\",\n",
    "        metadata={\"source\": \"dl.txt\", \"topic\": \"AI\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"FAISS es una librería para búsqueda eficiente de vectores similares.\",\n",
    "        metadata={\"source\": \"faiss.txt\", \"topic\": \"tools\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"Creados {len(documents)} documentos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando vector store con FAISS...\n",
      "Vector store creado con 5 vectores\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS vector store\n",
    "print(\"Creando vector store con FAISS...\")\n",
    "vector_store = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "print(f\"Vector store creado con {vector_store.index.ntotal} vectores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"loaders\"></a>\n",
    "## 3. Document Loaders\n",
    "\n",
    "LangChain proporciona loaders para cargar documentos desde múltiples fuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando contenido web...\n",
      "Documentos cargados: 1\n",
      "Caracteres: 55474\n",
      "Metadata: {'source': 'https://es.wikipedia.org/wiki/Python', 'title': 'Python - Wikipedia, la enciclopedia libre', 'language': 'es'}\n",
      "\n",
      "Primeros 500 caracteres:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Python - Wikipedia, la enciclopedia libre\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ir al contenido\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Menú principal\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Menú principal\n",
      "mover a la barra lateral\n",
      "ocultar\n",
      "\n",
      "\n",
      "\n",
      "\t\tNavegación\n",
      "\t\n",
      "\n",
      "\n",
      "PortadaPortal de la comunidadActualidadCambios recientesPáginas nuevasPágina aleatoriaAyudaNotificar un errorPáginas especiales\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Buscar\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Buscar\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Apariencia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donaciones\n",
      "\n",
      "Crear una cuenta\n",
      "\n",
      "Acceder\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Herramientas personales\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donaciones Crea...\n"
     ]
    }
   ],
   "source": [
    "# Web page loader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Load content from a web page\n",
    "print(\"Cargando contenido web...\")\n",
    "loader = WebBaseLoader(\"https://es.wikipedia.org/wiki/Python\")\n",
    "web_docs = loader.load()\n",
    "\n",
    "print(f\"Documentos cargados: {len(web_docs)}\")\n",
    "print(f\"Caracteres: {len(web_docs[0].page_content)}\")\n",
    "print(f\"Metadata: {web_docs[0].metadata}\")\n",
    "print(f\"\\nPrimeros 500 caracteres:\\n{web_docs[0].page_content[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento cargado: 1 archivo(s)\n",
      "Contenido:\n",
      "Introducción a la Inteligencia Artificial\n",
      "\n",
      "La inteligencia artificial (IA) es una rama de la informática que busca crear \n",
      "sistemas capaces de realizar tareas que normalmente requieren inteligencia humana.\n",
      "\n",
      "Tipos de IA:\n",
      "1. IA Débil (Narrow AI): Diseñada para tareas específicas\n",
      "2. IA Fuerte (General AI): Capaz de cualquier tarea intelectual humana\n",
      "3. Superinteligencia: Hipotética IA que supera la inteligencia humana\n",
      "\n",
      "Aplicaciones comunes:\n",
      "- Reconocimiento de voz\n",
      "- Visión por computadora\n",
      "- Procesamiento de lenguaje natural\n",
      "- Sistemas de recomendación\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text file loader (create a sample file first)\n",
    "sample_text = \"\"\"Introducción a la Inteligencia Artificial\n",
    "\n",
    "La inteligencia artificial (IA) es una rama de la informática que busca crear \n",
    "sistemas capaces de realizar tareas que normalmente requieren inteligencia humana.\n",
    "\n",
    "Tipos de IA:\n",
    "1. IA Débil (Narrow AI): Diseñada para tareas específicas\n",
    "2. IA Fuerte (General AI): Capaz de cualquier tarea intelectual humana\n",
    "3. Superinteligencia: Hipotética IA que supera la inteligencia humana\n",
    "\n",
    "Aplicaciones comunes:\n",
    "- Reconocimiento de voz\n",
    "- Visión por computadora\n",
    "- Procesamiento de lenguaje natural\n",
    "- Sistemas de recomendación\n",
    "\"\"\"\n",
    "\n",
    "# Save to file\n",
    "with open(\"sample_ai_doc.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "# Load from file\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "text_loader = TextLoader(\"sample_ai_doc.txt\", encoding=\"utf-8\")\n",
    "text_docs = text_loader.load()\n",
    "\n",
    "print(f\"Documento cargado: {len(text_docs)} archivo(s)\")\n",
    "print(f\"Contenido:\\n{text_docs[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"splitters\"></a>\n",
    "## 4. Text Splitters\n",
    "\n",
    "Los documentos largos deben dividirse en **chunks** (fragmentos) para:\n",
    "- Respetar límites de contexto del LLM\n",
    "- Mejorar precisión de búsqueda\n",
    "- Reducir costos de procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento original dividido en 5 chunks\n",
      "\n",
      "Chunk 1 (41 chars):\n",
      "  'Introducción a la Inteligencia Artificial...'\n",
      "\n",
      "Chunk 2 (161 chars):\n",
      "  'La inteligencia artificial (IA) es una rama de la informática que busca crear \n",
      "s...'\n",
      "\n",
      "Chunk 3 (141 chars):\n",
      "  'Tipos de IA:\n",
      "1. IA Débil (Narrow AI): Diseñada para tareas específicas\n",
      "2. IA Fue...'\n",
      "\n",
      "Chunk 4 (69 chars):\n",
      "  '3. Superinteligencia: Hipotética IA que supera la inteligencia humana...'\n",
      "\n",
      "Chunk 5 (134 chars):\n",
      "  'Aplicaciones comunes:\n",
      "- Reconocimiento de voz\n",
      "- Visión por computadora\n",
      "- Procesa...'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,        # Maximum characters per chunk\n",
    "    chunk_overlap=50,      # Overlap between chunks\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # Priority of separators\n",
    ")\n",
    "\n",
    "# Split the document\n",
    "chunks = text_splitter.split_documents(text_docs)\n",
    "\n",
    "print(f\"Documento original dividido en {len(chunks)} chunks\\n\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1} ({len(chunk.page_content)} chars):\")\n",
    "    print(f\"  '{chunk.page_content[:80]}...'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación de tamaños de chunk:\n",
      "==================================================\n",
      "chunk_size=100: 26 chunks\n",
      "chunk_size=200: 13 chunks\n",
      "chunk_size=500: 5 chunks\n"
     ]
    }
   ],
   "source": [
    "# Different chunk sizes comparison\n",
    "sizes = [100, 200, 500]\n",
    "\n",
    "long_text = web_docs[0].page_content[:2000]  # First 2000 chars from Wikipedia\n",
    "\n",
    "print(\"Comparación de tamaños de chunk:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for size in sizes:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=size,\n",
    "        chunk_overlap=size // 5  # 20% overlap\n",
    "    )\n",
    "    chunks = splitter.split_text(long_text)\n",
    "    print(f\"chunk_size={size}: {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrategia de chunking\n",
    "\n",
    "| Chunk Size | Ventajas | Desventajas |\n",
    "|------------|----------|-------------|\n",
    "| Pequeño (100-300) | Más preciso, específico | Puede perder contexto |\n",
    "| Mediano (300-800) | Balance contexto/precisión | Uso general |\n",
    "| Grande (800-2000) | Más contexto | Menos preciso, más tokens |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"search\"></a>\n",
    "## 5. Similarity Search\n",
    "\n",
    "La búsqueda por similitud es la operación fundamental de los vector stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store con 10 documentos\n"
     ]
    }
   ],
   "source": [
    "# Create vector store with more documents\n",
    "all_chunks = text_splitter.split_documents(text_docs)\n",
    "\n",
    "# Add more sample documents\n",
    "extra_docs = [\n",
    "    Document(page_content=\"Los transformers revolucionaron el NLP en 2017.\", \n",
    "             metadata={\"topic\": \"NLP\"}),\n",
    "    Document(page_content=\"GPT-4 es un modelo de lenguaje desarrollado por OpenAI.\",\n",
    "             metadata={\"topic\": \"LLM\"}),\n",
    "    Document(page_content=\"BERT es un modelo bidireccional pre-entrenado.\",\n",
    "             metadata={\"topic\": \"NLP\"}),\n",
    "    Document(page_content=\"Las redes convolucionales son excelentes para imágenes.\",\n",
    "             metadata={\"topic\": \"CV\"}),\n",
    "    Document(page_content=\"El aprendizaje por refuerzo entrena agentes mediante recompensas.\",\n",
    "             metadata={\"topic\": \"RL\"}),\n",
    "]\n",
    "\n",
    "all_docs = all_chunks + extra_docs\n",
    "\n",
    "# Create new vector store\n",
    "vs = FAISS.from_documents(all_docs, embeddings)\n",
    "print(f\"Vector store con {vs.index.ntotal} documentos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: '¿Qué es el procesamiento de lenguaje natural?'\n",
      "\n",
      "Resultados:\n",
      "==================================================\n",
      "\n",
      "1. BERT es un modelo bidireccional pre-entrenado.\n",
      "   Metadata: {'topic': 'NLP'}\n",
      "\n",
      "2. GPT-4 es un modelo de lenguaje desarrollado por OpenAI.\n",
      "   Metadata: {'topic': 'LLM'}\n",
      "\n",
      "3. Las redes convolucionales son excelentes para imágenes.\n",
      "   Metadata: {'topic': 'CV'}\n"
     ]
    }
   ],
   "source": [
    "# Basic similarity search\n",
    "query = \"¿Qué es el procesamiento de lenguaje natural?\"\n",
    "\n",
    "results = vs.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"\\nResultados:\")\n",
    "print(\"=\" * 50)\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. {doc.page_content}\")\n",
    "    print(f\"   Metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: '¿Qué es el procesamiento de lenguaje natural?'\n",
      "\n",
      "Resultados con puntuación (menor = más similar):\n",
      "==================================================\n",
      "\n",
      "Score: 1.1154\n",
      "  BERT es un modelo bidireccional pre-entrenado.\n",
      "\n",
      "Score: 1.1231\n",
      "  GPT-4 es un modelo de lenguaje desarrollado por OpenAI.\n",
      "\n",
      "Score: 1.1309\n",
      "  Las redes convolucionales son excelentes para imágenes.\n"
     ]
    }
   ],
   "source": [
    "# Similarity search with scores\n",
    "results_with_scores = vs.similarity_search_with_score(query, k=3)\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"\\nResultados con puntuación (menor = más similar):\")\n",
    "print(\"=\" * 50)\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"\\nScore: {score:.4f}\")\n",
    "    print(f\"  {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Búsqueda filtrada (topic='NLP'):\n",
      "  - BERT es un modelo bidireccional pre-entrenado.\n",
      "  - Los transformers revolucionaron el NLP en 2017.\n"
     ]
    }
   ],
   "source": [
    "# Search with metadata filter\n",
    "# Note: FAISS doesn't support native filtering, but we can post-filter\n",
    "\n",
    "def search_with_filter(vector_store, query, k=10, filter_key=None, filter_value=None):\n",
    "    \"\"\"Search with optional metadata filtering.\"\"\"\n",
    "    # Get more results to filter\n",
    "    results = vector_store.similarity_search(query, k=k)\n",
    "    \n",
    "    if filter_key and filter_value:\n",
    "        results = [doc for doc in results \n",
    "                   if doc.metadata.get(filter_key) == filter_value]\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Search only NLP documents\n",
    "nlp_results = search_with_filter(vs, \"modelos de lenguaje\", filter_key=\"topic\", filter_value=\"NLP\")\n",
    "\n",
    "print(\"Búsqueda filtrada (topic='NLP'):\")\n",
    "for doc in nlp_results[:3]:\n",
    "    print(f\"  - {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever: Interfaz para búsqueda\n",
    "\n",
    "LangChain proporciona una interfaz `Retriever` para usar vector stores en chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever devolvió 3 documentos:\n",
      "  - La inteligencia artificial (IA) es una rama de la informátic...\n",
      "  - Introducción a la Inteligencia Artificial...\n",
      "  - 3. Superinteligencia: Hipotética IA que supera la inteligenc...\n"
     ]
    }
   ],
   "source": [
    "# Create retriever from vector store\n",
    "retriever = vs.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "# Use retriever\n",
    "docs = retriever.invoke(\"inteligencia artificial\")\n",
    "\n",
    "print(f\"Retriever devolvió {len(docs)} documentos:\")\n",
    "for doc in docs:\n",
    "    print(f\"  - {doc.page_content[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"persistencia\"></a>\n",
    "## 6. Persistencia y carga\n",
    "\n",
    "FAISS permite guardar y cargar el índice para no tener que recalcular embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store guardado en 'faiss_index/'\n"
     ]
    }
   ],
   "source": [
    "# Save vector store to disk\n",
    "vs.save_local(\"faiss_index\")\n",
    "print(\"Vector store guardado en 'faiss_index/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store cargado con 10 vectores\n",
      "Test búsqueda: Tipos de IA:\n",
      "1. IA Débil (Narrow AI): Diseñada par...\n"
     ]
    }
   ],
   "source": [
    "# Load vector store from disk\n",
    "loaded_vs = FAISS.load_local(\n",
    "    \"faiss_index\", \n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True  # Required for pickle files\n",
    ")\n",
    "\n",
    "print(f\"Vector store cargado con {loaded_vs.index.ntotal} vectores\")\n",
    "\n",
    "# Test that it works\n",
    "test_results = loaded_vs.similarity_search(\"IA\", k=1)\n",
    "print(f\"Test búsqueda: {test_results[0].page_content[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectores después de añadir: 12\n"
     ]
    }
   ],
   "source": [
    "# Add more documents to existing vector store\n",
    "new_docs = [\n",
    "    Document(page_content=\"LangChain facilita el desarrollo de aplicaciones con LLMs.\",\n",
    "             metadata={\"topic\": \"tools\"}),\n",
    "    Document(page_content=\"Hugging Face es la plataforma líder para modelos de ML.\",\n",
    "             metadata={\"topic\": \"tools\"}),\n",
    "]\n",
    "\n",
    "# Add to vector store\n",
    "loaded_vs.add_documents(new_docs)\n",
    "\n",
    "print(f\"Vectores después de añadir: {loaded_vs.index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ejercicios\"></a>\n",
    "## 7. Ejercicios Prácticos\n",
    "\n",
    "### Ejercicio 1: Crear un buscador de FAQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sistema FAQ:\n",
      "Q: olvidé mi clave\n",
      "A: Lunes a Viernes de 9:00 a 18:00.\n",
      "\n",
      "Q: quiero devolver algo\n",
      "A: Lunes a Viernes de 9:00 a 18:00.\n",
      "\n",
      "Q: ¿envían a México?\n",
      "A: Sí, enviamos a más de 50 países.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: FAQ Search System\n",
    "\n",
    "faqs = [\n",
    "    {\"q\": \"¿Cómo puedo resetear mi contraseña?\", \n",
    "     \"a\": \"Ve a 'Olvidé mi contraseña' en la página de login.\"},\n",
    "    {\"q\": \"¿Cuál es el horario de atención?\",\n",
    "     \"a\": \"Lunes a Viernes de 9:00 a 18:00.\"},\n",
    "    {\"q\": \"¿Aceptan devoluciones?\",\n",
    "     \"a\": \"Sí, tienes 30 días para devolver productos sin usar.\"},\n",
    "    {\"q\": \"¿Tienen envío internacional?\",\n",
    "     \"a\": \"Sí, enviamos a más de 50 países.\"},\n",
    "    {\"q\": \"¿Cómo contacto con soporte?\",\n",
    "     \"a\": \"Email: soporte@ejemplo.com o chat en vivo.\"},\n",
    "]\n",
    "\n",
    "# Create documents with questions and answers\n",
    "faq_docs = [\n",
    "    Document(\n",
    "        page_content=faq[\"q\"],\n",
    "        metadata={\"answer\": faq[\"a\"]}\n",
    "    )\n",
    "    for faq in faqs\n",
    "]\n",
    "\n",
    "# Create vector store\n",
    "faq_vs = FAISS.from_documents(faq_docs, embeddings)\n",
    "\n",
    "# Search function\n",
    "def find_answer(query):\n",
    "    results = faq_vs.similarity_search(query, k=1)\n",
    "    if results:\n",
    "        return results[0].metadata[\"answer\"]\n",
    "    return \"No encontré una respuesta.\"\n",
    "\n",
    "# Test\n",
    "test_queries = [\n",
    "    \"olvidé mi clave\",\n",
    "    \"quiero devolver algo\",\n",
    "    \"¿envían a México?\"\n",
    "]\n",
    "\n",
    "print(\"Sistema FAQ:\")\n",
    "for q in test_queries:\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"A: {find_answer(q)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Comparar diferentes chunk sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'aplicaciones de IA en salud'\n",
      "\n",
      "Chunk size=100: 11 chunks\n",
      "  Mejor resultado: 'En el sector salud, la IA ayuda a diagnosticar enfermedades ...'\n",
      "\n",
      "Chunk size=200: 5 chunks\n",
      "  Mejor resultado: 'El comercio electrónico utiliza IA para personalizar recomen...'\n",
      "\n",
      "Chunk size=400: 3 chunks\n",
      "  Mejor resultado: 'En finanzas, los modelos predictivos ayudan a detectar fraud...'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Experiment with chunk sizes\n",
    "# Load a longer document and test different chunk sizes\n",
    "\n",
    "# Create a longer sample document\n",
    "long_document = \"\"\"\n",
    "La inteligencia artificial ha transformado numerosas industrias en las últimas décadas.\n",
    "Desde el reconocimiento de voz hasta los vehículos autónomos, las aplicaciones son vastas.\n",
    "\n",
    "En el sector salud, la IA ayuda a diagnosticar enfermedades con mayor precisión.\n",
    "Los algoritmos pueden analizar imágenes médicas y detectar anomalías que los humanos podrían pasar por alto.\n",
    "\n",
    "En finanzas, los modelos predictivos ayudan a detectar fraudes y evaluar riesgos crediticios.\n",
    "Los chatbots atienden consultas de clientes las 24 horas del día.\n",
    "\n",
    "El comercio electrónico utiliza IA para personalizar recomendaciones de productos.\n",
    "Los sistemas analizan el historial de compras y navegación para sugerir artículos relevantes.\n",
    "\n",
    "Sin embargo, la IA también plantea desafíos éticos importantes.\n",
    "La privacidad de datos, el sesgo algorítmico y el desplazamiento laboral son temas críticos.\n",
    "\"\"\"\n",
    "\n",
    "# Test different chunk sizes and see search quality\n",
    "chunk_sizes = [100, 200, 400]\n",
    "query = \"aplicaciones de IA en salud\"\n",
    "\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "\n",
    "for size in chunk_sizes:\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=size, chunk_overlap=20)\n",
    "    chunks = splitter.create_documents([long_document])\n",
    "    vs_test = FAISS.from_documents(chunks, embeddings)\n",
    "    results = vs_test.similarity_search(query, k=1)\n",
    "    \n",
    "    print(f\"Chunk size={size}: {len(chunks)} chunks\")\n",
    "    print(f\"  Mejor resultado: '{results[0].page_content[:60]}...'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "En este notebook hemos aprendido:\n",
    "\n",
    "1. **Vector Stores**: Bases de datos para búsqueda semántica\n",
    "2. **FAISS**: Vector store local, rápido y gratuito\n",
    "3. **Document Loaders**: Cargar desde archivos, web, PDFs\n",
    "4. **Text Splitters**: Dividir documentos en chunks\n",
    "5. **Similarity Search**: Buscar por significado\n",
    "6. **Persistencia**: Guardar y cargar índices\n",
    "\n",
    "### Arquitectura típica de un sistema de retrieval\n",
    "\n",
    "```\n",
    "Documentos → [Loader] → [Splitter] → [Embeddings] → [Vector Store]\n",
    "                                                         ↓\n",
    "Query → [Embedding] → [Similarity Search] → Documentos relevantes\n",
    "```\n",
    "\n",
    "En el siguiente notebook veremos cómo combinar esto con LLMs para crear sistemas **RAG** (Retrieval-Augmented Generation).\n",
    "\n",
    "---\n",
    "\n",
    "## Referencias\n",
    "\n",
    "- [FAISS Documentation](https://faiss.ai/)\n",
    "- [LangChain Vector Stores](https://python.langchain.com/docs/modules/data_connection/vectorstores/)\n",
    "- [Chunking Strategies](https://www.pinecone.io/learn/chunking-strategies/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "langchain_community         0.4.1\n",
      "langchain_core              1.2.9\n",
      "langchain_huggingface       NA\n",
      "langchain_text_splitters    NA\n",
      "session_info                v1.0.1\n",
      "-----\n",
      "IPython             9.10.0\n",
      "jupyter_client      8.8.0\n",
      "jupyter_core        5.9.1\n",
      "-----\n",
      "Python 3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]\n",
      "Windows-11-10.0.26200-SP0\n",
      "-----\n",
      "Session information updated at 2026-02-09 16:07\n"
     ]
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show(html = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA_LLM",
   "language": "python",
   "name": "ia_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
