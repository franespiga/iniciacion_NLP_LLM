{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Chatbots B√°sicos\n",
    "\n",
    "## Curso de LLMs y Aplicaciones de IA\n",
    "\n",
    "**Duraci√≥n estimada:** 1.5-2 horas\n",
    "\n",
    "---\n",
    "\n",
    "## √çndice\n",
    "\n",
    "1. [Introducci√≥n a los Chatbots](#intro)\n",
    "2. [Chatbot con reglas simples](#reglas)\n",
    "3. [Chatbot con LLM (API gratuita)](#llm)\n",
    "4. [A√±adiendo memoria a la conversaci√≥n](#memoria)\n",
    "5. [Interfaces con Streamlit](#streamlit)\n",
    "6. [Ejercicios pr√°cticos](#ejercicios)\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos de aprendizaje\n",
    "\n",
    "Al finalizar este notebook, ser√°s capaz de:\n",
    "- Entender los diferentes tipos de chatbots\n",
    "- Construir un chatbot b√°sico con reglas\n",
    "- Integrar un LLM para respuestas inteligentes\n",
    "- Implementar memoria conversacional\n",
    "- Crear interfaces de usuario con Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"intro\"></a>\n",
    "## 1. Introducci√≥n a los Chatbots\n",
    "\n",
    "### Tipos de chatbots\n",
    "\n",
    "| Tipo | Descripci√≥n | Ejemplo |\n",
    "|------|-------------|--------|\n",
    "| **Basado en reglas** | Respuestas predefinidas, keywords | FAQ bots simples |\n",
    "| **Retrieval-based** | Busca respuestas en base de conocimiento | Customer support |\n",
    "| **Generativo (LLM)** | Genera respuestas din√°micamente | ChatGPT, Claude |\n",
    "| **H√≠brido** | Combina reglas + LLM | Asistentes empresariales |\n",
    "\n",
    "### Arquitectura b√°sica de un chatbot\n",
    "\n",
    "```\n",
    "Usuario ‚Üí [Input] ‚Üí [Procesamiento] ‚Üí [Generaci√≥n] ‚Üí [Output] ‚Üí Usuario\n",
    "                          ‚Üë\n",
    "                     [Memoria/Contexto]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "#!pip install -q langchain langchain-groq langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Introduce tu GROQ API Key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key configurada ‚úì\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Setup Groq API (FREE tier)\n",
    "if 'GROQ_API_KEY' not in os.environ:\n",
    "    os.environ['GROQ_API_KEY'] = getpass(\"Introduce tu GROQ API Key: \")\n",
    "\n",
    "print(\"API Key configurada ‚úì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"reglas\"></a>\n",
    "## 2. Chatbot con reglas simples\n",
    "\n",
    "El chatbot m√°s simple utiliza coincidencia de palabras clave para seleccionar respuestas predefinidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot basado en reglas:\n",
      "==================================================\n",
      "üë§ Usuario: Hola, ¬øqu√© tal?\n",
      "ü§ñ Bot: ¬°Hola! ¬øEn qu√© puedo ayudarte?\n",
      "\n",
      "üë§ Usuario: ¬øCu√°l es el precio del producto?\n",
      "ü§ñ Bot: Nuestros precios var√≠an seg√∫n el producto. ¬øCu√°l te interesa?\n",
      "\n",
      "üë§ Usuario: ¬øCu√°l es su horario?\n",
      "ü§ñ Bot: Nuestro horario es de 9:00 a 18:00, de lunes a viernes.\n",
      "\n",
      "üë§ Usuario: Quiero comprar un coche\n",
      "ü§ñ Bot: Lo siento, no entend√≠ tu pregunta. ¬øPuedes reformularla?\n",
      "\n",
      "üë§ Usuario: Gracias por la ayuda\n",
      "ü§ñ Bot: ¬°De nada! ¬øNecesitas algo m√°s?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class RuleBasedChatbot:\n",
    "    \"\"\"Simple rule-based chatbot using keyword matching.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Define rules as keyword -> response mappings\n",
    "        self.rules = {\n",
    "            'hola': '¬°Hola! ¬øEn qu√© puedo ayudarte?',\n",
    "            'buenos d√≠as': '¬°Buenos d√≠as! ¬øC√≥mo est√°s?',\n",
    "            'adi√≥s': '¬°Hasta luego! Que tengas un buen d√≠a.',\n",
    "            'gracias': '¬°De nada! ¬øNecesitas algo m√°s?',\n",
    "            'precio': 'Nuestros precios var√≠an seg√∫n el producto. ¬øCu√°l te interesa?',\n",
    "            'horario': 'Nuestro horario es de 9:00 a 18:00, de lunes a viernes.',\n",
    "            'contacto': 'Puedes contactarnos en info@ejemplo.com o al 900 123 456.',\n",
    "            'ayuda': 'Puedo ayudarte con: precios, horarios, contacto. ¬øQu√© necesitas?'\n",
    "        }\n",
    "        self.default_response = \"Lo siento, no entend√≠ tu pregunta. ¬øPuedes reformularla?\"\n",
    "    \n",
    "    def respond(self, user_input: str) -> str:\n",
    "        \"\"\"Generate response based on keyword matching.\"\"\"\n",
    "        user_input_lower = user_input.lower()\n",
    "        \n",
    "        # Check each rule\n",
    "        for keyword, response in self.rules.items():\n",
    "            if keyword in user_input_lower:\n",
    "                return response\n",
    "        \n",
    "        return self.default_response\n",
    "\n",
    "# Test the rule-based chatbot\n",
    "bot = RuleBasedChatbot()\n",
    "\n",
    "test_messages = [\n",
    "    \"Hola, ¬øqu√© tal?\",\n",
    "    \"¬øCu√°l es el precio del producto?\",\n",
    "    \"¬øCu√°l es su horario?\",\n",
    "    \"Quiero comprar un coche\",  # No matching rule\n",
    "    \"Gracias por la ayuda\"\n",
    "]\n",
    "\n",
    "print(\"Chatbot basado en reglas:\")\n",
    "print(\"=\" * 50)\n",
    "for msg in test_messages:\n",
    "    response = bot.respond(msg)\n",
    "    print(f\"üë§ Usuario: {msg}\")\n",
    "    print(f\"ü§ñ Bot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitaciones del chatbot basado en reglas\n",
    "\n",
    "| ‚úÖ Ventajas | ‚ùå Desventajas |\n",
    "|------------|---------------|\n",
    "| R√°pido y predecible | No entiende contexto |\n",
    "| Sin costos de API | Respuestas limitadas |\n",
    "| F√°cil de mantener | No maneja variaciones |\n",
    "| Control total | No aprende |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"llm\"></a>\n",
    "## 3. Chatbot con LLM (API gratuita)\n",
    "\n",
    "Ahora crearemos un chatbot m√°s inteligente usando un LLM a trav√©s de Groq (tier gratuito)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\git\\docencia\\iniciacion_NLP_LLM\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot con LLM:\n",
      "==================================================\n",
      "üë§ Usuario: Hola, ¬øqu√© tal?\n",
      "ü§ñ Bot: Hola, estoy bien, gracias. ¬øEn qu√© puedo ayudarte hoy?\n",
      "\n",
      "üë§ Usuario: ¬øPuedes explicarme qu√© es machine learning en t√©rminos simples?\n",
      "ü§ñ Bot: **Machine Learning** (Aprendizaje Autom√°tico) es una t√©cnica que permite a las computadoras **aprender** de los datos y mejorar su rendimiento en tareas espec√≠ficas, sin necesidad de ser programadas expl√≠citamente.\n",
      "\n",
      "Imagina que quieres ense√±ar a un ni√±o a reconocer perros y gatos. En lugar de explicarle todas las caracter√≠sticas de cada animal, le muestras muchas fotos de perros y gatos y le dices \"este es un perro\" o \"este es un gato\". Con el tiempo, el ni√±o aprender√° a reconocerlos por s√≠ mismo.\n",
      "\n",
      "De manera similar, el machine learning funciona entrenando a una computadora con una gran cantidad de datos y permiti√©ndole aprender patrones y relaciones, para que pueda tomar decisiones o realizar tareas de manera aut√≥noma.\n",
      "\n",
      "**Ejemplos comunes:**\n",
      "\n",
      "* Reconocimiento de im√°genes\n",
      "* Predicci√≥n de comportamientos\n",
      "* Clasificaci√≥n de textos\n",
      "* Recomendaciones de productos\n",
      "\n",
      "En resumen, el machine learning es una forma de hacer que las computadoras aprendan de los datos y tomen decisiones inteligentes, sin necesidad de programaci√≥n expl√≠cita.\n",
      "\n",
      "üë§ Usuario: Quiero comprar un coche, ¬øqu√© consejos me das?\n",
      "ü§ñ Bot: ¬°Claro! Aqu√≠ te dejo algunos consejos para comprar un coche:\n",
      "\n",
      "1. **Define tu presupuesto**: Establece cu√°nto est√°s dispuesto a gastar, incluyendo el precio del coche, impuestos, seguro y mantenimiento.\n",
      "2. **Investiga y compara**: Busca diferentes modelos y marcas, y compara sus caracter√≠sticas, precios y rese√±as de otros propietarios.\n",
      "3. **Verifica el historial del veh√≠culo**: Si est√°s considerando un coche usado, obt√©n un informe de historial del veh√≠culo para asegurarte de que no tenga problemas ocultos.\n",
      "4. **Prueba el coche**: Conduce el coche antes de comprarlo para asegurarte de que te sientas c√≥modo y de que funcione adecuadamente.\n",
      "5. **Negocia el precio**: No tengas miedo de negociar el precio con el vendedor, especialmente si est√°s comprando un coche usado.\n",
      "6. **Considera los costos de mantenimiento**: Investiga los costos de mantenimiento y reparaci√≥n del coche para asegurarte de que se ajusten a tu presupuesto.\n",
      "7. **Lee y entiende el contrato**: Antes de firmar, aseg√∫rate de leer y entender todas las condiciones del contrato de compra.\n",
      "\n",
      "Espero que estos consejos te sean √∫tiles. ¬øTienes alguna pregunta espec√≠fica sobre el proceso de compra de un coche?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "class LLMChatbot:\n",
    "    \"\"\"Chatbot powered by LLM (using free Groq API).\"\"\"\n",
    "    \n",
    "    def __init__(self, system_prompt: str = None):\n",
    "        self.llm = ChatGroq(\n",
    "            model_name=\"llama-3.3-70b-versatile\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Default system prompt\n",
    "        self.system_prompt = system_prompt or \"\"\"Eres un asistente amable y servicial.\n",
    "        Responde de forma concisa y clara.\n",
    "        Si no sabes algo, dilo honestamente.\"\"\"\n",
    "    \n",
    "    def respond(self, user_input: str) -> str:\n",
    "        \"\"\"Generate response using LLM.\"\"\"\n",
    "        messages = [\n",
    "            SystemMessage(content=self.system_prompt),\n",
    "            HumanMessage(content=user_input)\n",
    "        ]\n",
    "        \n",
    "        response = self.llm.invoke(messages)\n",
    "        return response.content\n",
    "\n",
    "# Test the LLM chatbot\n",
    "llm_bot = LLMChatbot()\n",
    "\n",
    "test_messages = [\n",
    "    \"Hola, ¬øqu√© tal?\",\n",
    "    \"¬øPuedes explicarme qu√© es machine learning en t√©rminos simples?\",\n",
    "    \"Quiero comprar un coche, ¬øqu√© consejos me das?\"\n",
    "]\n",
    "\n",
    "print(\"Chatbot con LLM:\")\n",
    "print(\"=\" * 50)\n",
    "for msg in test_messages:\n",
    "    print(f\"üë§ Usuario: {msg}\")\n",
    "    response = llm_bot.respond(msg)\n",
    "    print(f\"ü§ñ Bot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot especializado con rol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot de Soporte T√©cnico:\n",
      "==================================================\n",
      "üë§ Usuario: Mi laptop no enciende, ¬øqu√© puedo hacer?\n",
      "ü§ñ Bot: Lo siento mucho que est√©s experimentando problemas con tu laptop. Aqu√≠ te dejo algunos pasos que puedes seguir para intentar solucionar el problema:\n",
      "\n",
      "1. **Verifica la fuente de alimentaci√≥n**: Aseg√∫rate de que el cable de alimentaci√≥n est√© correctamente conectado tanto a la laptop como a la toma de corriente. Tambi√©n puedes probar con un cable de alimentaci√≥n diferente para descartar cualquier problema con el cable.\n",
      "2. **Comprueba la bater√≠a**: Si tu laptop tiene una bater√≠a extra√≠ble, intenta quitarla y conectar el cable de alimentaci√≥n directamente a la laptop. Si se enciende, es posible que el problema est√© en la bater√≠a.\n",
      "3. **Presiona el bot√≥n de encendido durante un tiempo prolongado**: A veces, el bot√≥n de encendido puede estar atascado o tener un problema de contacto. Intenta presionar el bot√≥n de encendido durante 30 segundos para ver si se enciende.\n",
      "4. **Verifica si hay alg√∫n da√±o f√≠sico**: Revisa la laptop para ver si hay alg√∫n da√±o f√≠sico, como golpes o da√±os en la pantalla, que puedan estar impidiendo que se encienda.\n",
      "\n",
      "Si none de estos pasos soluciona el problema, es posible que el problema sea m√°s grave y requiera atenci√≥n t√©cnica.\n",
      "\n",
      "**¬øLa laptop est√° dentro del per√≠odo de garant√≠a?** Si es as√≠, podemos ayudarte a procesar una reparaci√≥n o reemplazo de acuerdo con nuestras pol√≠ticas de garant√≠a.\n",
      "\n",
      "**¬øQuieres que te ayude a programar una cita en una de nuestras tiendas para que un t√©cnico pueda revisar tu laptop?** O si prefieres, tambi√©n puedes enviarnos un correo electr√≥nico a soporte@techstore.com o llamarnos al 900 111 222 para obtener m√°s ayuda. Estamos aqu√≠ para ayudarte.\n",
      "\n",
      "üë§ Usuario: ¬øCu√°nto dura la garant√≠a de los smartphones?\n",
      "ü§ñ Bot: Nuestros smartphones vienen con una garant√≠a de 1 a√±o. Esto significa que, si tienes alg√∫n problema con tu dispositivo dentro de ese plazo, podr√°s contactarnos para obtener asistencia y, si es necesario, reparaci√≥n o reemplazo sin costo adicional.\n",
      "\n",
      "Si necesitas ayuda con tu smartphone, no dudes en hac√©rmelo saber. Estoy aqu√≠ para ayudarte. Puedes contactarnos a trav√©s de nuestro correo electr√≥nico (soporte@techstore.com) o llamando al 900 111 222, de lunes a viernes, de 9:00 a 18:00. ¬øHay algo m√°s en lo que pueda ayudarte?\n",
      "\n",
      "üë§ Usuario: ¬øTienen servicio de reparaci√≥n los fines de semana?\n",
      "ü§ñ Bot: Lo siento, pero nuestro servicio de soporte t√©cnico solo est√° disponible de lunes a viernes, de 9:00 a 18:00. Los fines de semana no ofrecemos servicio de reparaci√≥n ni atenci√≥n telef√≥nica.\n",
      "\n",
      "Si tienes un problema con tu dispositivo, te recomiendo enviarnos un correo electr√≥nico a soporte@techstore.com y nos pondremos en contacto contigo lo antes posible el lunes siguiente.\n",
      "\n",
      "Si el problema es urgente y requiere atenci√≥n presencial, te sugiero visitar una de nuestras tiendas durante nuestro horario de apertura. Estamos aqu√≠ para ayudarte de la mejor manera posible. ¬øHay algo m√°s en lo que pueda ayudarte?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a specialized chatbot for tech support\n",
    "tech_support_prompt = \"\"\"Eres un t√©cnico de soporte experto en productos tecnol√≥gicos.\n",
    "Tu empresa vende:\n",
    "- Laptops (garant√≠a 2 a√±os)\n",
    "- Smartphones (garant√≠a 1 a√±o)  \n",
    "- Tablets (garant√≠a 1 a√±o)\n",
    "\n",
    "Horario de soporte: Lunes a Viernes, 9:00-18:00\n",
    "Email: soporte@techstore.com\n",
    "Tel√©fono: 900 111 222\n",
    "\n",
    "Responde de forma profesional pero amigable.\n",
    "Si el problema requiere atenci√≥n presencial, recomienda visitar una tienda.\"\"\"\n",
    "\n",
    "tech_bot = LLMChatbot(system_prompt=tech_support_prompt)\n",
    "\n",
    "tech_questions = [\n",
    "    \"Mi laptop no enciende, ¬øqu√© puedo hacer?\",\n",
    "    \"¬øCu√°nto dura la garant√≠a de los smartphones?\",\n",
    "    \"¬øTienen servicio de reparaci√≥n los fines de semana?\"\n",
    "]\n",
    "\n",
    "print(\"Chatbot de Soporte T√©cnico:\")\n",
    "print(\"=\" * 50)\n",
    "for q in tech_questions:\n",
    "    print(f\"üë§ Usuario: {q}\")\n",
    "    response = tech_bot.respond(q)\n",
    "    print(f\"ü§ñ Bot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"memoria\"></a>\n",
    "## 4. A√±adiendo memoria a la conversaci√≥n\n",
    "\n",
    "Un chatbot sin memoria no puede mantener una conversaci√≥n coherente. Vamos a implementar memoria conversacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot con memoria:\n",
      "==================================================\n",
      "üë§ Usuario: Hola, me llamo Carlos.\n",
      "ü§ñ Bot: **Hola Carlos, ¬°encantado de conocerte!**\n",
      "\n",
      "Me alegra que hayas decidido interactuar conmigo. Estoy aqu√≠ para ayudarte en lo que necesites, ya sea responder a tus preguntas, proporcionarte informaci√≥n o simplemente charlar contigo.\n",
      "\n",
      "¬øEn qu√© puedo ayudarte hoy, Carlos? ¬øTienes alguna pregunta o tema en mente que te gustar√≠a discutir? Estoy aqu√≠ para escucharte y ayudarte en lo que pueda.\n",
      "\n",
      "üë§ Usuario: ¬øCu√°l es la capital de Francia?\n",
      "ü§ñ Bot: **La capital de Francia es Par√≠s**.\n",
      "\n",
      "Par√≠s es una de las ciudades m√°s famosas y emblem√°ticas del mundo, conocida por sus monumentos hist√≥ricos como la Torre Eiffel, el Louvre y Notre-Dame, as√≠ como por su rica cultura y estilo de vida.\n",
      "\n",
      "¬øTe gustar√≠a saber m√°s sobre Par√≠s o Francia en general? Estoy aqu√≠ para proporcionarte informaci√≥n y responder a tus preguntas.\n",
      "\n",
      "üë§ Usuario: ¬øY cu√°ntos habitantes tiene?\n",
      "ü§ñ Bot: **La poblaci√≥n de Par√≠s es de aproximadamente 2,1 millones de habitantes**.\n",
      "\n",
      "Sin embargo, si consideramos la regi√≥n metropolitana de Par√≠s, que se conoce como √éle-de-France, la poblaci√≥n asciende a m√°s de 12 millones de habitantes, lo que la convierte en una de las √°reas metropolitanas m√°s grandes de Europa.\n",
      "\n",
      "Aqu√≠ te dejo una breve estad√≠stica para que tengas una idea m√°s clara:\n",
      "\n",
      "* Poblaci√≥n de la ciudad de Par√≠s: 2,1 millones de habitantes\n",
      "* Poblaci√≥n de la regi√≥n metropolitana de Par√≠s (√éle-de-France): 12,2 millones de habitantes\n",
      "\n",
      "¬øTe gustar√≠a saber m√°s sobre la demograf√≠a o la econom√≠a de Par√≠s? Estoy aqu√≠ para proporcionarte informaci√≥n y responder a tus preguntas.\n",
      "\n",
      "üë§ Usuario: ¬øC√≥mo me llamo?\n",
      "ü§ñ Bot: **Te llamas Carlos**.\n",
      "\n",
      "Me acord√© de que me lo dijiste al principio de nuestra conversaci√≥n. ¬øNecesitas algo m√°s o quieres seguir charlando? Estoy aqu√≠ para ayudarte y conversar contigo.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ChatbotWithMemory:\n",
    "    \"\"\"Chatbot with conversation memory.\"\"\"\n",
    "    \n",
    "    def __init__(self, system_prompt: str = None):\n",
    "        self.llm = ChatGroq(\n",
    "            model_name=\"llama-3.3-70b-versatile\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        self.system_prompt = system_prompt or \"Eres un asistente amable y servicial.\"\n",
    "        \n",
    "        # Initialize conversation history\n",
    "        self.history = []\n",
    "    \n",
    "    def respond(self, user_input: str) -> str:\n",
    "        \"\"\"Generate response while maintaining conversation history.\"\"\"\n",
    "        # Build messages with history\n",
    "        messages = [SystemMessage(content=self.system_prompt)]\n",
    "        \n",
    "        # Add conversation history\n",
    "        for human_msg, ai_msg in self.history:\n",
    "            messages.append(HumanMessage(content=human_msg))\n",
    "            messages.append(AIMessage(content=ai_msg))\n",
    "        \n",
    "        # Add current message\n",
    "        messages.append(HumanMessage(content=user_input))\n",
    "        \n",
    "        # Get response\n",
    "        response = self.llm.invoke(messages)\n",
    "        ai_response = response.content\n",
    "        \n",
    "        # Save to history\n",
    "        self.history.append((user_input, ai_response))\n",
    "        \n",
    "        return ai_response\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear conversation history.\"\"\"\n",
    "        self.history = []\n",
    "        print(\"Historial borrado.\")\n",
    "\n",
    "# Test chatbot with memory\n",
    "memory_bot = ChatbotWithMemory()\n",
    "\n",
    "print(\"Chatbot con memoria:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Conversation that requires memory\n",
    "conversation = [\n",
    "    \"Hola, me llamo Carlos.\",\n",
    "    \"¬øCu√°l es la capital de Francia?\",\n",
    "    \"¬øY cu√°ntos habitantes tiene?\",\n",
    "    \"¬øC√≥mo me llamo?\"  # Test if bot remembers the name\n",
    "]\n",
    "\n",
    "for msg in conversation:\n",
    "    print(f\"üë§ Usuario: {msg}\")\n",
    "    response = memory_bot.respond(msg)\n",
    "    print(f\"ü§ñ Bot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historial de la conversaci√≥n:\n",
      "==================================================\n",
      "Turno 1:\n",
      "  üë§ Human: Hola, me llamo Carlos.\n",
      "  ü§ñ AI: **Hola Carlos, ¬°encantado de conocerte!**\n",
      "\n",
      "Me aleg...\n",
      "\n",
      "Turno 2:\n",
      "  üë§ Human: ¬øCu√°l es la capital de Francia?\n",
      "  ü§ñ AI: **La capital de Francia es Par√≠s**.\n",
      "\n",
      "Par√≠s es una ...\n",
      "\n",
      "Turno 3:\n",
      "  üë§ Human: ¬øY cu√°ntos habitantes tiene?\n",
      "  ü§ñ AI: **La poblaci√≥n de Par√≠s es de aproximadamente 2,1 ...\n",
      "\n",
      "Turno 4:\n",
      "  üë§ Human: ¬øC√≥mo me llamo?\n",
      "  ü§ñ AI: **Te llamas Carlos**.\n",
      "\n",
      "Me acord√© de que me lo diji...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show conversation history\n",
    "print(\"Historial de la conversaci√≥n:\")\n",
    "print(\"=\" * 50)\n",
    "for i, (human, ai) in enumerate(memory_bot.history, 1):\n",
    "    print(f\"Turno {i}:\")\n",
    "    print(f\"  üë§ Human: {human[:50]}...\" if len(human) > 50 else f\"  üë§ Human: {human}\")\n",
    "    print(f\"  ü§ñ AI: {ai[:50]}...\" if len(ai) > 50 else f\"  ü§ñ AI: {ai}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gesti√≥n de memoria: Sliding Window\n",
    "\n",
    "Para conversaciones largas, mantener todo el historial es costoso. Una soluci√≥n es usar una ventana deslizante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot con memoria de 3 turnos\n"
     ]
    }
   ],
   "source": [
    "class ChatbotWithSlidingWindow:\n",
    "    \"\"\"Chatbot with sliding window memory.\"\"\"\n",
    "    \n",
    "    def __init__(self, system_prompt: str = None, max_history: int = 5):\n",
    "        self.llm = ChatGroq(\n",
    "            model_name=\"llama-3.3-70b-versatile\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        self.system_prompt = system_prompt or \"Eres un asistente amable.\"\n",
    "        self.history = []\n",
    "        self.max_history = max_history  # Maximum number of turns to remember\n",
    "    \n",
    "    def respond(self, user_input: str) -> str:\n",
    "        \"\"\"Generate response with sliding window memory.\"\"\"\n",
    "        messages = [SystemMessage(content=self.system_prompt)]\n",
    "        \n",
    "        # Only include last N turns\n",
    "        recent_history = self.history[-self.max_history:]\n",
    "        \n",
    "        for human_msg, ai_msg in recent_history:\n",
    "            messages.append(HumanMessage(content=human_msg))\n",
    "            messages.append(AIMessage(content=ai_msg))\n",
    "        \n",
    "        messages.append(HumanMessage(content=user_input))\n",
    "        \n",
    "        response = self.llm.invoke(messages)\n",
    "        ai_response = response.content\n",
    "        \n",
    "        self.history.append((user_input, ai_response))\n",
    "        \n",
    "        return ai_response\n",
    "\n",
    "# Test sliding window\n",
    "sliding_bot = ChatbotWithSlidingWindow(max_history=3)\n",
    "print(f\"Bot con memoria de {sliding_bot.max_history} turnos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"streamlit\"></a>\n",
    "## 5. Interfaces con Streamlit\n",
    "\n",
    "**Streamlit** permite crear interfaces web interactivas f√°cilmente. A continuaci√≥n se muestra el c√≥digo para una aplicaci√≥n de chatbot.\n",
    "\n",
    "**Nota:** Este c√≥digo debe ejecutarse como script de Python, no en Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C√≥digo para Streamlit Chatbot:\n",
      "==================================================\n",
      "Guarda este c√≥digo como 'chatbot_app.py'\n",
      "Ejecuta con: streamlit run chatbot_app.py\n",
      "==================================================\n",
      "\n",
      "import streamlit as st\n",
      "from langchain_groq import ChatGroq\n",
      "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
      "import os\n",
      "\n",
      "# Page configuration\n",
      "st.set_page_config(\n",
      "    page_title=\"Chatbot con LLM\",\n",
      "    page_icon=\"ü§ñ\",\n",
      "    layout=\"centered\"\n",
      ")\n",
      "\n",
      "st.title(\"ü§ñ Chatbot con LLM\")\n",
      "\n",
      "# Sidebar for API key\n",
      "with st.sidebar:\n",
      "    st.header(\"Configuraci√≥n\")\n",
      "    api_key = st.text_input(\"GROQ API Key\", type=\"password\")\n",
      "\n",
      "    if api_key:\n",
      "        os.environ[\"GROQ_API_KEY\"] = api_key\n",
      "\n",
      "    if st.button(\"Limpiar historial\"):\n",
      "        st.session_state.messages = []\n",
      "        st.rerun()\n",
      "\n",
      "# Initialize session state for chat history\n",
      "if \"messages\" not in st.session_state:\n",
      "    st.session_state.messages = []\n",
      "\n",
      "# Display chat history\n",
      "for message in st.session_state.messages:\n",
      "    with st.chat_message(message[\"role\"]):\n",
      "        st.write(message[\"content\"])\n",
      "\n",
      "# Chat input\n",
      "if prompt := st.chat_input(\"Escribe tu mensaje...\"):\n",
      "    if not api_key:\n",
      "        st.error(\"Por favor, introduce tu API key en la barra lateral.\")\n",
      "    else:\n",
      "        # Add user message to history\n",
      "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
      "\n",
      "        with st.chat_message(\"user\"):\n",
      "            st.write(prompt)\n",
      "\n",
      "        # Generate response\n",
      "        with st.chat_message(\"assistant\"):\n",
      "            with st.spinner(\"Pensando...\"):\n",
      "                try:\n",
      "                    llm = ChatGroq(\n",
      "                        model_name=\"llama-3.3-70b-versatile\",\n",
      "                        temperature=0.7\n",
      "                    )\n",
      "\n",
      "                    # Build messages\n",
      "                    messages = [SystemMessage(content=\"Eres un asistente amable.\")]\n",
      "\n",
      "                    for msg in st.session_state.messages:\n",
      "                        if msg[\"role\"] == \"user\":\n",
      "                            messages.append(HumanMessage(content=msg[\"content\"]))\n",
      "                        else:\n",
      "                            messages.append(AIMessage(content=msg[\"content\"]))\n",
      "\n",
      "                    response = llm.invoke(messages)\n",
      "                    st.write(response.content)\n",
      "\n",
      "                    # Add assistant response to history\n",
      "                    st.session_state.messages.append({\n",
      "                        \"role\": \"assistant\", \n",
      "                        \"content\": response.content\n",
      "                    })\n",
      "\n",
      "                except Exception as e:\n",
      "                    st.error(f\"Error: {e}\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the code for a Streamlit chatbot app\n",
    "# Save as 'chatbot_app.py' and run with: streamlit run chatbot_app.py\n",
    "\n",
    "streamlit_code = '''\n",
    "import streamlit as st\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "import os\n",
    "\n",
    "# Page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"Chatbot con LLM\",\n",
    "    page_icon=\"ü§ñ\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "st.title(\"ü§ñ Chatbot con LLM\")\n",
    "\n",
    "# Sidebar for API key\n",
    "with st.sidebar:\n",
    "    st.header(\"Configuraci√≥n\")\n",
    "    api_key = st.text_input(\"GROQ API Key\", type=\"password\")\n",
    "    \n",
    "    if api_key:\n",
    "        os.environ[\"GROQ_API_KEY\"] = api_key\n",
    "    \n",
    "    if st.button(\"Limpiar historial\"):\n",
    "        st.session_state.messages = []\n",
    "        st.rerun()\n",
    "\n",
    "# Initialize session state for chat history\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Display chat history\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.write(message[\"content\"])\n",
    "\n",
    "# Chat input\n",
    "if prompt := st.chat_input(\"Escribe tu mensaje...\"):\n",
    "    if not api_key:\n",
    "        st.error(\"Por favor, introduce tu API key en la barra lateral.\")\n",
    "    else:\n",
    "        # Add user message to history\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "        with st.chat_message(\"user\"):\n",
    "            st.write(prompt)\n",
    "        \n",
    "        # Generate response\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            with st.spinner(\"Pensando...\"):\n",
    "                try:\n",
    "                    llm = ChatGroq(\n",
    "                        model_name=\"llama-3.3-70b-versatile\",\n",
    "                        temperature=0.7\n",
    "                    )\n",
    "                    \n",
    "                    # Build messages\n",
    "                    messages = [SystemMessage(content=\"Eres un asistente amable.\")]\n",
    "                    \n",
    "                    for msg in st.session_state.messages:\n",
    "                        if msg[\"role\"] == \"user\":\n",
    "                            messages.append(HumanMessage(content=msg[\"content\"]))\n",
    "                        else:\n",
    "                            messages.append(AIMessage(content=msg[\"content\"]))\n",
    "                    \n",
    "                    response = llm.invoke(messages)\n",
    "                    st.write(response.content)\n",
    "                    \n",
    "                    # Add assistant response to history\n",
    "                    st.session_state.messages.append({\n",
    "                        \"role\": \"assistant\", \n",
    "                        \"content\": response.content\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    st.error(f\"Error: {e}\")\n",
    "'''\n",
    "\n",
    "print(\"C√≥digo para Streamlit Chatbot:\")\n",
    "print(\"=\"*50)\n",
    "print(\"Guarda este c√≥digo como 'chatbot_app.py'\")\n",
    "print(\"Ejecuta con: streamlit run chatbot_app.py\")\n",
    "print(\"=\"*50)\n",
    "print(streamlit_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Archivo 'chatbot_app.py' creado.\n",
      "Para ejecutar: streamlit run chatbot_app.py\n"
     ]
    }
   ],
   "source": [
    "# Save the Streamlit app to a file\n",
    "with open('chatbot_app.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(streamlit_code)\n",
    "\n",
    "print(\"‚úì Archivo 'chatbot_app.py' creado.\")\n",
    "print(\"Para ejecutar: streamlit run chatbot_app.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ejercicios\"></a>\n",
    "## 6. Ejercicios Pr√°cticos\n",
    "\n",
    "### Ejercicio 1: Chatbot FAQ personalizado\n",
    "\n",
    "Mejora el chatbot basado en reglas para manejar m√°s casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Create a more sophisticated rule-based chatbot\n",
    "# Add rules for:\n",
    "# - Product returns\n",
    "# - Payment methods\n",
    "# - Shipping information\n",
    "# - Opening hours\n",
    "\n",
    "class EnhancedRuleChatbot:\n",
    "    def __init__(self):\n",
    "        self.rules = {\n",
    "            # Add your rules here\n",
    "            'hola': '¬°Hola! ¬øEn qu√© puedo ayudarte?',\n",
    "            # 'devolucion': '...',\n",
    "            # 'pago': '...',\n",
    "            # etc.\n",
    "        }\n",
    "        self.default_response = \"No entend√≠. ¬øPuedes reformular?\"\n",
    "    \n",
    "    def respond(self, user_input: str) -> str:\n",
    "        user_input_lower = user_input.lower()\n",
    "        for keyword, response in self.rules.items():\n",
    "            if keyword in user_input_lower:\n",
    "                return response\n",
    "        return self.default_response\n",
    "\n",
    "# Test your chatbot\n",
    "# enhanced_bot = EnhancedRuleChatbot()\n",
    "# print(enhanced_bot.respond(\"¬øC√≥mo puedo devolver un producto?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Chatbot con personalidad\n",
    "\n",
    "Crea un chatbot con una personalidad espec√≠fica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Create a chatbot with a specific personality\n",
    "# Ideas:\n",
    "# - A pirate who speaks in pirate language\n",
    "# - A Yoda-like character\n",
    "# - A formal butler\n",
    "# - A cheerful fitness coach\n",
    "\n",
    "personality_prompt = \"\"\"\n",
    "# Define your personality prompt here\n",
    "# Include:\n",
    "# - Character description\n",
    "# - Speaking style\n",
    "# - Typical phrases\n",
    "# - Topics they're expert in\n",
    "\"\"\"\n",
    "\n",
    "# personality_bot = LLMChatbot(system_prompt=personality_prompt)\n",
    "# Test with some messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3: Chatbot h√≠brido\n",
    "\n",
    "Combina reglas con LLM: usa reglas para casos conocidos y LLM para el resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Hybrid chatbot (rules + LLM)\n",
    "\n",
    "class HybridChatbot:\n",
    "    \"\"\"Chatbot that uses rules for known cases and LLM for others.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Define rules for FAQ\n",
    "        self.rules = {\n",
    "            'horario': 'Horario: L-V 9:00-18:00',\n",
    "            'precio': 'Consulta precios en www.ejemplo.com/precios',\n",
    "            # Add more rules...\n",
    "        }\n",
    "        \n",
    "        # LLM for complex questions\n",
    "        self.llm = ChatGroq(\n",
    "            model_name=\"llama-3.3-70b-versatile\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "    \n",
    "    def respond(self, user_input: str) -> str:\n",
    "        # First, try rules\n",
    "        user_input_lower = user_input.lower()\n",
    "        for keyword, response in self.rules.items():\n",
    "            if keyword in user_input_lower:\n",
    "                return f\"[REGLA] {response}\"\n",
    "        \n",
    "        # If no rule matches, use LLM\n",
    "        messages = [\n",
    "            SystemMessage(content=\"Eres un asistente de tienda online.\"),\n",
    "            HumanMessage(content=user_input)\n",
    "        ]\n",
    "        response = self.llm.invoke(messages)\n",
    "        return f\"[LLM] {response.content}\"\n",
    "\n",
    "# Test hybrid chatbot\n",
    "# hybrid = HybridChatbot()\n",
    "# print(hybrid.respond(\"¬øCu√°l es el horario?\"))  # Should use rule\n",
    "# print(hybrid.respond(\"¬øQu√© opinas del cambio clim√°tico?\"))  # Should use LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "En este notebook hemos aprendido:\n",
    "\n",
    "1. **Chatbots basados en reglas**: Simples pero limitados\n",
    "2. **Chatbots con LLM**: Inteligentes y flexibles\n",
    "3. **Memoria conversacional**: Fundamental para coherencia\n",
    "4. **Sliding window**: Gesti√≥n eficiente de memoria\n",
    "5. **Streamlit**: Interfaces web interactivas\n",
    "\n",
    "### Tipos de memoria en chatbots\n",
    "\n",
    "| Tipo | Descripci√≥n | Uso |\n",
    "|------|-------------|-----|\n",
    "| Sin memoria | Cada mensaje es independiente | Consultas simples |\n",
    "| Memoria completa | Guarda todo el historial | Conversaciones cortas |\n",
    "| Sliding window | Guarda √∫ltimos N turnos | Conversaciones largas |\n",
    "| Resumen | Guarda resumen de la conversaci√≥n | Conversaciones muy largas |\n",
    "\n",
    "En el siguiente notebook veremos **Vector Stores y Retrieval**, fundamentales para crear chatbots con acceso a informaci√≥n externa.\n",
    "\n",
    "---\n",
    "\n",
    "## Referencias\n",
    "\n",
    "- [LangChain Chat Models](https://python.langchain.com/docs/modules/model_io/chat/)\n",
    "- [Streamlit Documentation](https://docs.streamlit.io/)\n",
    "- [Groq Console](https://console.groq.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "ipykernel           7.2.0\n",
      "langchain_core      1.2.9\n",
      "langchain_groq      1.1.2\n",
      "session_info        v1.0.1\n",
      "-----\n",
      "IPython             9.10.0\n",
      "jupyter_client      8.8.0\n",
      "jupyter_core        5.9.1\n",
      "-----\n",
      "Python 3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]\n",
      "Windows-11-10.0.26200-SP0\n",
      "-----\n",
      "Session information updated at 2026-02-09 16:02\n"
     ]
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show(html =False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA_LLM",
   "language": "python",
   "name": "ia_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
