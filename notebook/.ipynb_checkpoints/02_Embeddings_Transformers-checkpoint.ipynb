{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Embeddings con Transformers\n",
    "\n",
    "## Curso de LLMs y Aplicaciones de IA\n",
    "\n",
    "**Duración estimada:** 2-2.5 horas\n",
    "\n",
    "---\n",
    "\n",
    "## Índice\n",
    "\n",
    "1. [De Word2Vec a Transformers](#intro)\n",
    "2. [BERT: El primer Transformer contextual](#bert)\n",
    "3. [Sentence Transformers](#sentence)\n",
    "   - 3.1 Modelos Open Source\n",
    "   - 3.2 Búsqueda semántica\n",
    "4. [Visualización con UMAP](#umap)\n",
    "5. [Embeddings de proveedores comerciales](#comercial)\n",
    "6. [Ejercicios prácticos](#ejercicios)\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos de aprendizaje\n",
    "\n",
    "Al finalizar este notebook, serás capaz de:\n",
    "- Comprender la diferencia entre embeddings estáticos y contextuales\n",
    "- Utilizar BERT y Sentence Transformers para generar embeddings\n",
    "- Implementar búsqueda semántica con similitud coseno\n",
    "- Visualizar embeddings en 3D con UMAP\n",
    "- Conocer las opciones comerciales disponibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"intro\"></a>\n",
    "## 1. De Word2Vec a Transformers\n",
    "\n",
    "### El problema de los embeddings estáticos\n",
    "\n",
    "En el notebook anterior vimos Word2Vec y GloVe. Estos modelos tienen una limitación fundamental: **generan un único vector por palabra**, sin importar el contexto.\n",
    "\n",
    "**Ejemplo del problema:**\n",
    "- \"Voy al **banco** a sacar dinero\" (institución financiera)\n",
    "- \"Me senté en el **banco** del parque\" (asiento)\n",
    "- \"Vimos un **banco** de peces\" (grupo de animales)\n",
    "\n",
    "En Word2Vec, las tres oraciones usarían el **mismo vector** para \"banco\", perdiendo el significado contextual.\n",
    "\n",
    "### Evolución histórica\n",
    "\n",
    "| Modelo | Año | Tipo | Características |\n",
    "|--------|-----|------|----------------|\n",
    "| Word2Vec | 2013 | Estático | Un vector por palabra |\n",
    "| ELMo | 2018 | Contextual (BiLSTM) | Primer modelo contextual |\n",
    "| BERT | 2018 | Contextual (Transformer) | Bidireccional, atención |\n",
    "| Sentence-BERT | 2019 | Sentence-level | Embeddings de oraciones |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación de dependencias\n",
    "\n",
    "Todas las librerías usadas son **gratuitas y open source**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (all free and open source)\n",
    "#!pip install -q transformers sentence-transformers torch\n",
    "#!pip install -q umap-learn plotly scikit-learn\n",
    "#!pip install -q tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert\"></a>\n",
    "## 2. BERT: El primer Transformer contextual\n",
    "\n",
    "### ¿Qué es BERT?\n",
    "\n",
    "**BERT** (Bidirectional Encoder Representations from Transformers) fue desarrollado por Google en 2018. Sus características principales son:\n",
    "\n",
    "- **Bidireccional**: Lee toda la oración simultáneamente (no izquierda-a-derecha)\n",
    "- **Contextual**: Genera diferentes embeddings según el contexto\n",
    "- **Pre-entrenado**: Entrenado en grandes corpus, ajustable para tareas específicas\n",
    "\n",
    "### Arquitectura de BERT\n",
    "\n",
    "| Modelo | Capas | Heads | Parámetros | Dimensión |\n",
    "|--------|-------|-------|------------|----------|\n",
    "| BERT-Base | 12 | 12 | 110M | 768 |\n",
    "| BERT-Large | 24 | 16 | 340M | 1024 |\n",
    "\n",
    "### Tareas de pre-entrenamiento\n",
    "\n",
    "1. **Masked Language Modeling (MLM)**: Predecir palabras enmascaradas\n",
    "   - Entrada: \"El [MASK] ladra fuerte\"\n",
    "   - Salida: \"perro\"\n",
    "\n",
    "2. **Next Sentence Prediction (NSP)**: ¿Es B la siguiente oración de A?\n",
    "   - A: \"El cliente hizo el pedido.\"\n",
    "   - B: \"El sistema registró el pago.\" → [IsNext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando BERT base (inglés)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|█████████████████████████████████████████████████████████████████████| 199/199 [00:00<00:00, 738.35it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: bert-base-uncased\n",
      "Key                                        | Status     |  | \n",
      "-------------------------------------------+------------+--+-\n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED |  | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED |  | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED |  | \n",
      "cls.seq_relationship.weight                | UNEXPECTED |  | \n",
      "cls.predictions.bias                       | UNEXPECTED |  | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED |  | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained BERT model (English)\n",
    "print(\"Cargando BERT base (inglés)...\")\n",
    "tokenizer_bert = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model_bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model_bert.eval()  # Set to evaluation mode\n",
    "\n",
    "print(f\"Modelo cargado: bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: 'The bank approved my loan application'\n",
      "Tokens: ['[CLS]', 'the', 'bank', 'approved', 'my', 'loan', 'application', '[SEP]']\n",
      "Shape de embeddings: torch.Size([1, 8, 768])\n",
      "  - Batch size: 1\n",
      "  - Número de tokens: 8\n",
      "  - Dimensión del embedding: 768\n"
     ]
    }
   ],
   "source": [
    "# Example: Get BERT embeddings\n",
    "text = \"The bank approved my loan application\"\n",
    "\n",
    "# Tokenize and get embeddings\n",
    "tokens = tokenizer_bert(text, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_bert(**tokens)\n",
    "\n",
    "# Get embeddings from last hidden state\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "print(f\"Texto: '{text}'\")\n",
    "print(f\"Tokens: {tokenizer_bert.convert_ids_to_tokens(tokens['input_ids'][0])}\")\n",
    "print(f\"Shape de embeddings: {embeddings.shape}\")\n",
    "print(f\"  - Batch size: {embeddings.shape[0]}\")\n",
    "print(f\"  - Número de tokens: {embeddings.shape[1]}\")\n",
    "print(f\"  - Dimensión del embedding: {embeddings.shape[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT en español\n",
    "\n",
    "Existen modelos BERT entrenados específicamente en español. Uno de los más populares es **BETO**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando BETO (BERT español)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|████████████████████████████████████████████████████| 197/197 [00:00<00:00, 643.80it/s, Materializing param=encoder.layer.11.output.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: dccuchile/bert-base-spanish-wwm-cased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "bert.embeddings.position_ids               | UNEXPECTED | \n",
      "cls.predictions.decoder.weight             | UNEXPECTED | \n",
      "cls.predictions.decoder.bias               | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "pooler.dense.bias                          | MISSING    | \n",
      "pooler.dense.weight                        | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado: dccuchile/bert-base-spanish-wwm-cased\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load Spanish BERT model (BETO)\n",
    "print(\"Cargando BETO (BERT español)...\")\n",
    "modelo_id = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "tokenizer_es = AutoTokenizer.from_pretrained(modelo_id)\n",
    "model_es = AutoModel.from_pretrained(modelo_id)\n",
    "model_es.eval()\n",
    "\n",
    "print(f\"Modelo cargado: {modelo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: 'El banco central ajustó las tasas de interés'\n",
      "Tokens: ['[CLS]', 'El', 'banco', 'central', 'ajust', '##ó', 'las', 'tasas', 'de', 'interés', '[SEP]']\n",
      "Shape de embeddings: torch.Size([1, 11, 768])\n"
     ]
    }
   ],
   "source": [
    "# Test with Spanish text\n",
    "texto_es = \"El banco central ajustó las tasas de interés\"\n",
    "\n",
    "tokens_es = tokenizer_es(texto_es, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs_es = model_es(**tokens_es)\n",
    "\n",
    "embeddings_es = outputs_es.last_hidden_state\n",
    "\n",
    "print(f\"Texto: '{texto_es}'\")\n",
    "print(f\"Tokens: {tokenizer_es.convert_ids_to_tokens(tokens_es['input_ids'][0])}\")\n",
    "print(f\"Shape de embeddings: {embeddings_es.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de modelos\n",
    "\n",
    "| Modelo | Idiomas | Embeddings Contextuales | Bidireccional | Subpalabras |\n",
    "|--------|---------|------------------------|---------------|-------------|\n",
    "| Word2Vec | Mono | ❌ | ❌ | ❌ |\n",
    "| GloVe | Mono | ❌ | ❌ | ❌ |\n",
    "| ELMo | Mono | ✅ | Parcial | ❌ |\n",
    "| BERT | Multi | ✅ | ✅ | ✅ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"sentence\"></a>\n",
    "## 3. Sentence Transformers\n",
    "\n",
    "### El problema de BERT para oraciones\n",
    "\n",
    "BERT genera un embedding **por cada token**. Para obtener un embedding de toda la oración, necesitamos agregar estos vectores (promedio, CLS token, etc.), lo cual no es óptimo.\n",
    "\n",
    "### ¿Qué es Sentence Transformers?\n",
    "\n",
    "**Sentence Transformers** es una librería construida sobre HuggingFace que:\n",
    "- Genera un **único vector** por oración/párrafo\n",
    "- Optimizado para **similitud semántica**\n",
    "- Perfecto para búsqueda semántica, clustering, clasificación\n",
    "\n",
    "### Modelos populares\n",
    "\n",
    "| Modelo | Idiomas | Dimensiones | Uso recomendado |\n",
    "|--------|---------|-------------|----------------|\n",
    "| all-MiniLM-L6-v2 | Multi | 384 | Rápido, buena precisión |\n",
    "| all-mpnet-base-v2 | Multi | 768 | Mejor precisión |\n",
    "| paraphrase-multilingual-MiniLM-L12-v2 | Multi | 384 | Multilingüe |\n",
    "| hiiamsid/sentence_similarity_spanish_es | ES | 768 | Español específico |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo Sentence Transformer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|█████████████████████████████████████████████████████████████████████| 103/103 [00:00<00:00, 903.00it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado: all-MiniLM-L6-v2\n",
      "Dimensión del embedding: 384\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load Sentence Transformer model (free, open source)\n",
    "print(\"Cargando modelo Sentence Transformer...\")\n",
    "model_st = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "print(f\"Modelo cargado: all-MiniLM-L6-v2\")\n",
    "print(f\"Dimensión del embedding: 384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oración: 'Artificial intelligence is transforming the world.'\n",
      "Tipo: <class 'numpy.ndarray'>\n",
      "Shape: (384,)\n",
      "Primeros 10 valores: [ 0.03872415 -0.00110554  0.08271617 -0.01628858  0.04654316 -0.00953029\n",
      " -0.02997494  0.00349416  0.01119625  0.00263021]\n"
     ]
    }
   ],
   "source": [
    "# Generate sentence embedding\n",
    "sentence = \"Artificial intelligence is transforming the world.\"\n",
    "embedding = model_st.encode(sentence)\n",
    "\n",
    "print(f\"Oración: '{sentence}'\")\n",
    "print(f\"Tipo: {type(embedding)}\")\n",
    "print(f\"Shape: {embedding.shape}\")\n",
    "print(f\"Primeros 10 valores: {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Búsqueda Semántica\n",
    "\n",
    "Una de las aplicaciones más importantes de Sentence Transformers es la **búsqueda semántica**: encontrar documentos similares a una consulta basándose en el significado, no solo en palabras clave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta: '¿Cómo puedo abrir una cuenta bancaria?'\n",
      "\n",
      "Candidatos: 8 oraciones\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "# Query and candidate sentences\n",
    "query = \"¿Cómo puedo abrir una cuenta bancaria?\"\n",
    "\n",
    "candidates = [\n",
    "    \"Para abrir una cuenta bancaria, visita una sucursal con tu DNI.\",\n",
    "    \"Las cuentas bancarias se abren en línea fácilmente.\",\n",
    "    \"El banco central bajó los tipos de interés.\",\n",
    "    \"Me gusta el helado de vainilla.\",\n",
    "    \"Este es un buen banco para sentarse.\",\n",
    "    \"Ayer vi nadando en el mar un banco de peces.\",\n",
    "    \"Los requisitos incluyen identificación y comprobante de domicilio.\",\n",
    "    \"El clima está muy agradable hoy.\"\n",
    "]\n",
    "\n",
    "print(f\"Consulta: '{query}'\")\n",
    "print(f\"\\nCandidatos: {len(candidates)} oraciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados ordenados por similitud semántica:\n",
      "============================================================\n",
      "✅ 0.7862 | Las cuentas bancarias se abren en línea fácilmente.\n",
      "✅ 0.7175 | Para abrir una cuenta bancaria, visita una sucursal con tu DNI.\n",
      "✅ 0.5885 | Me gusta el helado de vainilla.\n",
      "✅ 0.4977 | El clima está muy agradable hoy.\n",
      "✅ 0.4875 | Este es un buen banco para sentarse.\n",
      "✅ 0.4612 | Los requisitos incluyen identificación y comprobante de domicilio.\n",
      "✅ 0.4605 | Ayer vi nadando en el mar un banco de peces.\n",
      "✅ 0.4342 | El banco central bajó los tipos de interés.\n"
     ]
    }
   ],
   "source": [
    "# Encode query and candidates\n",
    "query_embedding = model_st.encode(query, convert_to_tensor=True)\n",
    "candidate_embeddings = model_st.encode(candidates, convert_to_tensor=True)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarities = util.cos_sim(query_embedding, candidate_embeddings)[0]\n",
    "\n",
    "# Sort by similarity\n",
    "results = sorted(zip(candidates, similarities.tolist()), \n",
    "                key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Resultados ordenados por similitud semántica:\")\n",
    "print(\"=\" * 60)\n",
    "for sentence, score in results:\n",
    "    emoji = \"✅\" if score > 0.4 else \"❌\"\n",
    "    print(f\"{emoji} {score:.4f} | {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones de la búsqueda semántica\n",
    "\n",
    "Nota cómo el modelo:\n",
    "- **Entiende el contexto**: Relaciona \"abrir cuenta\" con \"requisitos\" e \"identificación\"\n",
    "- **Distingue homónimos**: Diferencia \"banco\" (financiero) de \"banco\" (asiento) y \"banco\" (peces)\n",
    "- **Ignora irrelevantes**: Baja puntuación para oraciones sin relación semántica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'What documents do I need for banking?'\n",
      "\n",
      "  0.2873 | El banco central bajó los tipos de interés.\n",
      "  0.2243 | Ayer vi nadando en el mar un banco de peces.\n",
      "  0.2236 | Este es un buen banco para sentarse.\n"
     ]
    }
   ],
   "source": [
    "# Function for semantic search\n",
    "def semantic_search(query, documents, model, top_k=5):\n",
    "    \"\"\"\n",
    "    Perform semantic search on documents.\n",
    "    \n",
    "    Parameters:\n",
    "    - query: search query string\n",
    "    - documents: list of document strings\n",
    "    - model: SentenceTransformer model\n",
    "    - top_k: number of results to return\n",
    "    \n",
    "    Returns:\n",
    "    - list of (document, score) tuples\n",
    "    \"\"\"\n",
    "    query_emb = model.encode(query, convert_to_tensor=True)\n",
    "    doc_embs = model.encode(documents, convert_to_tensor=True)\n",
    "    \n",
    "    similarities = util.cos_sim(query_emb, doc_embs)[0]\n",
    "    \n",
    "    # Get top-k indices\n",
    "    top_indices = similarities.argsort(descending=True)[:top_k]\n",
    "    \n",
    "    results = [(documents[i], similarities[i].item()) for i in top_indices]\n",
    "    return results\n",
    "\n",
    "# Test the function\n",
    "new_query = \"What documents do I need for banking?\"\n",
    "results = semantic_search(new_query, candidates, model_st, top_k=3)\n",
    "\n",
    "print(f\"Query: '{new_query}'\\n\")\n",
    "for doc, score in results:\n",
    "    print(f\"  {score:.4f} | {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"umap\"></a>\n",
    "## 4. Visualización con UMAP\n",
    "\n",
    "**UMAP** (Uniform Manifold Approximation and Projection) es un algoritmo de reducción de dimensionalidad que preserva mejor la estructura local que PCA, ideal para visualizar embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de oraciones: 16\n",
      "Categorías: {'Finance', 'Technology', 'Food', 'Animals'}\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "import plotly.express as px\n",
    "\n",
    "# Sample sentences for visualization\n",
    "sentences = [\n",
    "    # Animals\n",
    "    \"The dog barks in the garden\",\n",
    "    \"The cat sleeps on the couch\",\n",
    "    \"The bird sings in the morning\",\n",
    "    \"The horse runs in the field\",\n",
    "    # Technology\n",
    "    \"Artificial intelligence is advancing rapidly\",\n",
    "    \"Machine learning requires lots of data\",\n",
    "    \"Neural networks learn patterns automatically\",\n",
    "    \"Deep learning powers modern AI applications\",\n",
    "    # Finance\n",
    "    \"The stock market crashed yesterday\",\n",
    "    \"Banks offer different interest rates\",\n",
    "    \"Investment requires careful planning\",\n",
    "    \"The economy is recovering slowly\",\n",
    "    # Food\n",
    "    \"Pizza is my favorite food\",\n",
    "    \"I love eating sushi for dinner\",\n",
    "    \"The restaurant serves excellent pasta\",\n",
    "    \"Cooking at home is healthier\"\n",
    "]\n",
    "\n",
    "categories = (\n",
    "    [\"Animals\"] * 4 + \n",
    "    [\"Technology\"] * 4 + \n",
    "    [\"Finance\"] * 4 + \n",
    "    [\"Food\"] * 4\n",
    ")\n",
    "\n",
    "print(f\"Total de oraciones: {len(sentences)}\")\n",
    "print(f\"Categorías: {set(categories)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de embeddings: (16, 384)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "embeddings_viz = model_st.encode(sentences)\n",
    "print(f\"Shape de embeddings: {embeddings_viz.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape después de UMAP: (16, 3)\n"
     ]
    }
   ],
   "source": [
    "# Apply UMAP for 3D visualization\n",
    "reducer = umap.UMAP(n_components=3, random_state=42, n_neighbors=5)\n",
    "embeddings_3d = reducer.fit_transform(embeddings_viz)\n",
    "\n",
    "print(f\"Shape después de UMAP: {embeddings_3d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Categoría=Animals<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>text=%{text}<extra></extra>",
         "legendgroup": "Animals",
         "marker": {
          "color": "#636efa",
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Animals",
         "scene": "scene",
         "showlegend": true,
         "text": [
          "The dog barks in the garden",
          "The cat sleeps on the couch",
          "The bird sings in the morning",
          "The horse runs in the field"
         ],
         "type": "scatter3d",
         "x": {
          "bdata": "POILQSNFCkFWUQtBe64BQQ==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "CJR1Pkm7QT/i9Bc/A0UxPw==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "VDTEQIlDzkAh1rhAxhC/QA==",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "Categoría=Technology<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>text=%{text}<extra></extra>",
         "legendgroup": "Technology",
         "marker": {
          "color": "#EF553B",
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Technology",
         "scene": "scene",
         "showlegend": true,
         "text": [
          "Artificial intelligence is advancing rapidly",
          "Machine learning requires lots of data",
          "Neural networks learn patterns automatically",
          "Deep learning powers modern AI applications"
         ],
         "type": "scatter3d",
         "x": {
          "bdata": "vc/QQImbwkBcIb5AbtaxQA==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "9YwpQDuxIkApnAxA5cwlQA==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "fPC/QArxsUBctb1Am/y7QA==",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "Categoría=Finance<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>text=%{text}<extra></extra>",
         "legendgroup": "Finance",
         "marker": {
          "color": "#00cc96",
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Finance",
         "scene": "scene",
         "showlegend": true,
         "text": [
          "The stock market crashed yesterday",
          "Banks offer different interest rates",
          "Investment requires careful planning",
          "The economy is recovering slowly"
         ],
         "type": "scatter3d",
         "x": {
          "bdata": "f1rsQJkk+UBwIuRAZUDiQA==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "p0MdQKAtnz+RcglAR2I5QA==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "RWyvQEynxECHaL1Ae5uuQA==",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "Categoría=Food<br>x=%{x}<br>y=%{y}<br>z=%{z}<br>text=%{text}<extra></extra>",
         "legendgroup": "Food",
         "marker": {
          "color": "#ab63fa",
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Food",
         "scene": "scene",
         "showlegend": true,
         "text": [
          "Pizza is my favorite food",
          "I love eating sushi for dinner",
          "The restaurant serves excellent pasta",
          "Cooking at home is healthier"
         ],
         "type": "scatter3d",
         "x": {
          "bdata": "1dK0QBNTukBissFADpCrQA==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "c/ajvwSmbr/EHam/TB6tvw==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "KpBaQNjTPUAUnEdAlFc+QA==",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "height": 700,
        "legend": {
         "title": {
          "text": "Categoría"
         },
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "UMAP 1"
          }
         },
         "yaxis": {
          "title": {
           "text": "UMAP 2"
          }
         },
         "zaxis": {
          "title": {
           "text": "UMAP 3"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Embeddings de oraciones (Sentence-BERT + UMAP 3D)"
        },
        "width": 900
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3D visualization with Plotly\n",
    "fig = px.scatter_3d(\n",
    "    x=embeddings_3d[:, 0],\n",
    "    y=embeddings_3d[:, 1],\n",
    "    z=embeddings_3d[:, 2],\n",
    "    text=sentences,\n",
    "    color=categories,\n",
    "    title=\"Embeddings de oraciones (Sentence-BERT + UMAP 3D)\",\n",
    "    labels={'color': 'Categoría'}\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='UMAP 1',\n",
    "        yaxis_title='UMAP 2',\n",
    "        zaxis_title='UMAP 3'\n",
    "    ),\n",
    "    width=900,\n",
    "    height=700\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones de la visualización\n",
    "\n",
    "En el gráfico 3D podemos observar:\n",
    "- Las oraciones de la misma categoría tienden a agruparse\n",
    "- UMAP preserva la estructura semántica mejor que PCA\n",
    "- Los clusters están bien separados\n",
    "\n",
    "Esto demuestra que los Sentence Transformers capturan efectivamente el significado semántico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"comercial\"></a>\n",
    "## 5. Embeddings de proveedores comerciales (Opcional)\n",
    "\n",
    "Además de los modelos open source, existen embeddings comerciales de alta calidad:\n",
    "\n",
    "### OpenAI Embeddings\n",
    "| Modelo | Dimensiones | Precio (aprox) |\n",
    "|--------|-------------|----------------|\n",
    "| text-embedding-3-small | 1536 | $0.00002/1K tokens |\n",
    "| text-embedding-3-large | 3072 | $0.00013/1K tokens |\n",
    "\n",
    "### Google Gemini Embeddings\n",
    "| Modelo | Dimensiones | Precio |\n",
    "|--------|-------------|--------|\n",
    "| text-embedding-004 | 768 | Gratis (límites) |\n",
    "| gemini-embedding-exp | 768-3072 | Variable |\n",
    "\n",
    "**Nota:** Para este curso, usamos modelos open source para evitar costos. Los modelos comerciales pueden ofrecer mejor rendimiento en algunos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El código para embeddings comerciales está comentado.\n",
      "Para usarlo, descomenta y añade tu API key.\n"
     ]
    }
   ],
   "source": [
    "# Example code for OpenAI embeddings (requires API key)\n",
    "# Uncomment and add your API key to use\n",
    "\n",
    "# from openai import OpenAI\n",
    "# \n",
    "# OPENAI_API_KEY = \"your-api-key-here\"\n",
    "# client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "# \n",
    "# response = client.embeddings.create(\n",
    "#     input=\"Sample text for embedding\",\n",
    "#     model=\"text-embedding-3-small\"\n",
    "# )\n",
    "# \n",
    "# embedding = response.data[0].embedding\n",
    "# print(f\"OpenAI embedding dimension: {len(embedding)}\")\n",
    "\n",
    "print(\"El código para embeddings comerciales está comentado.\")\n",
    "print(\"Para usarlo, descomenta y añade tu API key.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ejercicios\"></a>\n",
    "## 6. Ejercicios Prácticos\n",
    "\n",
    "### Ejercicio 1: Búsqueda semántica en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sistema de FAQ con búsqueda semántica\n",
      "==================================================\n",
      "\n",
      "Pregunta: 'Quiero devolver algo que compré'\n",
      "Respuestas más relevantes:\n",
      "  0.5646 | ¿Cuál es el horario de atención al cliente?\n",
      "  0.5578 | ¿Cómo realizo una devolución de producto?\n",
      "\n",
      "Pregunta: '¿Aceptan tarjeta de crédito?'\n",
      "Respuestas más relevantes:\n",
      "  0.6264 | ¿Cuáles son los métodos de pago aceptados?\n",
      "  0.6209 | ¿Cuál es el horario de atención al cliente?\n",
      "\n",
      "Pregunta: 'Olvidé mi clave de acceso'\n",
      "Respuestas más relevantes:\n",
      "  0.5467 | ¿Cómo puedo cambiar mi contraseña?\n",
      "  0.5439 | ¿Cuál es el horario de atención al cliente?\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Create a semantic search system for FAQs\n",
    "\n",
    "faqs = [\n",
    "    \"¿Cuál es el horario de atención al cliente?\",\n",
    "    \"¿Cómo puedo cambiar mi contraseña?\",\n",
    "    \"¿Cuáles son los métodos de pago aceptados?\",\n",
    "    \"¿Cómo realizo una devolución de producto?\",\n",
    "    \"¿Tienen envío internacional?\",\n",
    "    \"¿Cuánto tiempo tarda el envío?\",\n",
    "    \"¿Puedo cancelar mi pedido?\",\n",
    "    \"¿Cómo contacto con soporte técnico?\"\n",
    "]\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"Quiero devolver algo que compré\",\n",
    "    \"¿Aceptan tarjeta de crédito?\",\n",
    "    \"Olvidé mi clave de acceso\"\n",
    "]\n",
    "\n",
    "print(\"Sistema de FAQ con búsqueda semántica\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in test_queries:\n",
    "    results = semantic_search(query, faqs, model_st, top_k=2)\n",
    "    print(f\"\\nPregunta: '{query}'\")\n",
    "    print(\"Respuestas más relevantes:\")\n",
    "    for faq, score in results:\n",
    "        print(f\"  {score:.4f} | {faq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Comparar diferentes modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación de modelos:\n",
      "============================================================\n",
      "\n",
      "Modelo: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|█████████████████████████████████████████████████████████████████████| 103/103 [00:00<00:00, 945.91it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dimensión: 384\n",
      "  Tiempo: 0.0184s para 3 textos\n",
      "\n",
      "Modelo: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|█████████████████████████████████████████████████████████████████████| 199/199 [00:00<00:00, 654.50it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dimensión: 384\n",
      "  Tiempo: 0.0454s para 3 textos\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Compare embedding dimensions and speed\n",
    "import time\n",
    "\n",
    "models_to_compare = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "]\n",
    "\n",
    "test_texts = [\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Deep learning uses neural networks with many layers.\",\n",
    "    \"Natural language processing enables computers to understand text.\"\n",
    "]\n",
    "\n",
    "print(\"Comparación de modelos:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for model_name in models_to_compare:\n",
    "    print(f\"\\nModelo: {model_name}\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    start = time.time()\n",
    "    embeddings = model.encode(test_texts)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"  Dimensión: {embeddings.shape[1]}\")\n",
    "    print(f\"  Tiempo: {elapsed:.4f}s para {len(test_texts)} textos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3: Clustering semántico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering semántico (sin etiquetas previas):\n",
      "==================================================\n",
      "\n",
      "Cluster 0:\n",
      "  - Football is played with 11 players\n",
      "  - Basketball requires a hoop and ball\n",
      "  - Tennis is played on a court\n",
      "\n",
      "Cluster 1:\n",
      "  - Pizza originated in Italy\n",
      "  - Sushi is a Japanese dish\n",
      "  - Tacos are popular in Mexico\n",
      "\n",
      "Cluster 2:\n",
      "  - Python is a popular programming language\n",
      "  - JavaScript runs in web browsers\n",
      "  - Machine learning requires data\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: Semantic clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "mixed_sentences = [\n",
    "    # Tech (cluster 0)\n",
    "    \"Python is a popular programming language\",\n",
    "    \"JavaScript runs in web browsers\",\n",
    "    \"Machine learning requires data\",\n",
    "    # Sports (cluster 1)  \n",
    "    \"Football is played with 11 players\",\n",
    "    \"Basketball requires a hoop and ball\",\n",
    "    \"Tennis is played on a court\",\n",
    "    # Food (cluster 2)\n",
    "    \"Pizza originated in Italy\",\n",
    "    \"Sushi is a Japanese dish\",\n",
    "    \"Tacos are popular in Mexico\"\n",
    "]\n",
    "\n",
    "# Get embeddings\n",
    "embs = model_st.encode(mixed_sentences)\n",
    "\n",
    "# Apply K-Means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(embs)\n",
    "\n",
    "print(\"Clustering semántico (sin etiquetas previas):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for cluster_id in range(3):\n",
    "    print(f\"\\nCluster {cluster_id}:\")\n",
    "    for sent, c in zip(mixed_sentences, clusters):\n",
    "        if c == cluster_id:\n",
    "            print(f\"  - {sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "En este notebook hemos aprendido:\n",
    "\n",
    "1. **Embeddings contextuales**: BERT genera diferentes vectores según el contexto\n",
    "2. **Sentence Transformers**: Embeddings optimizados para oraciones completas\n",
    "3. **Búsqueda semántica**: Encontrar documentos por significado, no palabras\n",
    "4. **Visualización UMAP**: Reducción de dimensionalidad preservando estructura\n",
    "\n",
    "### Cuándo usar cada modelo\n",
    "\n",
    "| Caso de uso | Modelo recomendado |\n",
    "|-------------|-------------------|\n",
    "| Búsqueda semántica rápida | all-MiniLM-L6-v2 |\n",
    "| Multilingüe | paraphrase-multilingual-MiniLM-L12-v2 |\n",
    "| Máxima precisión | all-mpnet-base-v2 |\n",
    "| Español específico | BETO o hiiamsid/sentence_similarity_spanish_es |\n",
    "\n",
    "En el siguiente notebook veremos **Ingeniería de Prompts**, fundamental para trabajar con LLMs.\n",
    "\n",
    "---\n",
    "\n",
    "## Referencias\n",
    "\n",
    "- [BERT Paper (Devlin et al., 2018)](https://arxiv.org/abs/1810.04805)\n",
    "- [Sentence-BERT Paper (Reimers & Gurevych, 2019)](https://arxiv.org/abs/1908.10084)\n",
    "- [Sentence Transformers Documentation](https://www.sbert.net/)\n",
    "- [HuggingFace Transformers](https://huggingface.co/docs/transformers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "numpy                       2.3.5\n",
      "plotly                      6.5.2\n",
      "sentence_transformers       5.2.2\n",
      "session_info                v1.0.1\n",
      "sklearn                     1.8.0\n",
      "torch                       2.10.0+cpu\n",
      "transformers                5.1.0\n",
      "umap                        0.5.11\n",
      "-----\n",
      "IPython             9.10.0\n",
      "jupyter_client      8.8.0\n",
      "jupyter_core        5.9.1\n",
      "-----\n",
      "Python 3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]\n",
      "Windows-11-10.0.26200-SP0\n",
      "-----\n",
      "Session information updated at 2026-02-09 15:38\n"
     ]
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show(html = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA_LLM",
   "language": "python",
   "name": "ia_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
