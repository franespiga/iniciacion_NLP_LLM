{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 - RAG Avanzado: Agentic RAG\n",
    "\n",
    "## Curso de LLMs y Aplicaciones de IA\n",
    "\n",
    "**DuraciÃ³n estimada:** 2.5-3 horas\n",
    "\n",
    "---\n",
    "\n",
    "## Ãndice\n",
    "\n",
    "1. [Â¿QuÃ© es Agentic RAG?](#intro)\n",
    "2. [Arquitectura completa](#arquitectura)\n",
    "3. [ImplementaciÃ³n paso a paso](#implementacion)\n",
    "4. [EvaluaciÃ³n con RAGAS](#evaluacion)\n",
    "5. [Mejores prÃ¡cticas de producciÃ³n](#produccion)\n",
    "6. [Ejercicio final](#ejercicio)\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos de aprendizaje\n",
    "\n",
    "Al finalizar este notebook, serÃ¡s capaz de:\n",
    "- DiseÃ±ar sistemas RAG agentic completos\n",
    "- Implementar evaluaciÃ³n de calidad con RAGAS\n",
    "- Aplicar patrones de producciÃ³n\n",
    "- Optimizar el rendimiento del sistema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"intro\"></a>\n",
    "## 1. Â¿QuÃ© es Agentic RAG?\n",
    "\n",
    "**Agentic RAG** combina las capacidades de:\n",
    "- **RAG**: Acceso a conocimiento externo\n",
    "- **Agentes**: Razonamiento y uso de herramientas\n",
    "- **Grafos**: Flujos de trabajo complejos\n",
    "\n",
    "### ComparaciÃ³n\n",
    "\n",
    "| RAG Simple | Agentic RAG |\n",
    "|------------|-------------|\n",
    "| Un paso de retrieval | MÃºltiples pasos adaptativos |\n",
    "| Sin razonamiento | Planifica y razona |\n",
    "| Query fija | Reformula queries |\n",
    "| Sin verificaciÃ³n | Auto-corrige respuestas |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q langchain langchain-groq langgraph langchain-huggingface faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "GROQ API Key:  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurado âœ“\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'GROQ_API_KEY' not in os.environ:\n",
    "    os.environ['GROQ_API_KEY'] = getpass(\"GROQ API Key: \")\n",
    "\n",
    "print(\"Configurado âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"arquitectura\"></a>\n",
    "## 2. Arquitectura Completa\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      AGENTIC RAG SYSTEM                        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                â”‚\n",
    "â”‚  Query â†’ [Clasificar] â†’ [Reformular?] â†’ [Retrieval]           â”‚\n",
    "â”‚              â†“                              â†“                  â”‚\n",
    "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”              [Verificar contexto]       â”‚\n",
    "â”‚     â”‚   FAQ?        â”‚                      â†“                  â”‚\n",
    "â”‚     â”‚   General?    â”‚              [Generar respuesta]        â”‚\n",
    "â”‚     â”‚   TÃ©cnica?    â”‚                      â†“                  â”‚\n",
    "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              [Verificar calidad]        â”‚\n",
    "â”‚                                            â†“                  â”‚\n",
    "â”‚                                    [Corregir si necesario]    â”‚\n",
    "â”‚                                            â†“                  â”‚\n",
    "â”‚                                    [Respuesta final]          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"implementacion\"></a>\n",
    "## 3. ImplementaciÃ³n paso a paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 972.18it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Componentes inicializados âœ“\n"
     ]
    }
   ],
   "source": [
    "# Setup components\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import TypedDict, List, Literal\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0.3)\n",
    "\n",
    "# Create knowledge base\n",
    "knowledge_docs = [\n",
    "    Document(page_content=\"El IBI se paga anualmente y grava bienes inmuebles urbanos y rÃºsticos.\", \n",
    "             metadata={\"source\": \"ibi\", \"type\": \"definition\"}),\n",
    "    Document(page_content=\"El IVTM grava la titularidad de vehÃ­culos. Se paga mientras estÃ© matriculado.\",\n",
    "             metadata={\"source\": \"ivtm\", \"type\": \"definition\"}),\n",
    "    Document(page_content=\"Bonificaciones IBI: familias numerosas hasta 90%, energÃ­as renovables 50%.\",\n",
    "             metadata={\"source\": \"ibi\", \"type\": \"bonus\"}),\n",
    "    Document(page_content=\"Bonificaciones IVTM: vehÃ­culos elÃ©ctricos 75%, histÃ³ricos 100%.\",\n",
    "             metadata={\"source\": \"ivtm\", \"type\": \"bonus\"}),\n",
    "    Document(page_content=\"Plazos de pago: IBI segundo semestre, IVTM primer trimestre.\",\n",
    "             metadata={\"source\": \"general\", \"type\": \"deadlines\"}),\n",
    "    Document(page_content=\"Recursos: Puede interponer recurso en 30 dÃ­as desde la notificaciÃ³n.\",\n",
    "             metadata={\"source\": \"general\", \"type\": \"appeals\"}),\n",
    "]\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(knowledge_docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "print(\"Componentes inicializados âœ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones de nodo definidas âœ“\n"
     ]
    }
   ],
   "source": [
    "# Define state\n",
    "class AgenticRAGState(TypedDict):\n",
    "    question: str\n",
    "    question_type: str\n",
    "    reformulated_question: str\n",
    "    context: str\n",
    "    context_sufficient: bool\n",
    "    response: str\n",
    "    response_quality: str\n",
    "    final_response: str\n",
    "    iteration: int\n",
    "\n",
    "# Node functions\n",
    "def classify_question(state: AgenticRAGState) -> AgenticRAGState:\n",
    "    \"\"\"Classify the type of question.\"\"\"\n",
    "    prompt = f\"\"\"Clasifica esta pregunta en una de las categorÃ­as: DEFINITION, BONUS, DEADLINE, APPEAL, OTHER.\n",
    "    \n",
    "Pregunta: {state['question']}\n",
    "\n",
    "Responde solo con la categorÃ­a.\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    q_type = response.content.strip().upper()\n",
    "    return {**state, \"question_type\": q_type}\n",
    "\n",
    "def reformulate_question(state: AgenticRAGState) -> AgenticRAGState:\n",
    "    \"\"\"Reformulate question for better retrieval.\"\"\"\n",
    "    prompt = f\"\"\"Reformula esta pregunta para mejorar la bÃºsqueda de informaciÃ³n.\n",
    "MantÃ©n la esencia pero hazla mÃ¡s especÃ­fica.\n",
    "\n",
    "Pregunta original: {state['question']}\n",
    "\n",
    "Pregunta reformulada:\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"reformulated_question\": response.content.strip()}\n",
    "\n",
    "def retrieve_context(state: AgenticRAGState) -> AgenticRAGState:\n",
    "    \"\"\"Retrieve relevant documents.\"\"\"\n",
    "    query = state.get(\"reformulated_question\") or state[\"question\"]\n",
    "    docs = retriever.invoke(query)\n",
    "    context = \"\\n\".join([f\"- {d.page_content}\" for d in docs])\n",
    "    return {**state, \"context\": context}\n",
    "\n",
    "def check_context(state: AgenticRAGState) -> AgenticRAGState:\n",
    "    \"\"\"Check if context is sufficient.\"\"\"\n",
    "    prompt = f\"\"\"Â¿El contexto contiene informaciÃ³n relevante para responder la pregunta?\n",
    "    \n",
    "Pregunta: {state['question']}\n",
    "Contexto: {state['context']}\n",
    "\n",
    "Responde SI o NO.\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    sufficient = \"SI\" in response.content.upper()\n",
    "    return {**state, \"context_sufficient\": sufficient}\n",
    "\n",
    "def generate_response(state: AgenticRAGState) -> AgenticRAGState:\n",
    "    \"\"\"Generate response from context.\"\"\"\n",
    "    prompt = f\"\"\"Responde la pregunta basÃ¡ndote SOLO en el contexto proporcionado.\n",
    "Si no hay informaciÃ³n suficiente, indÃ­calo claramente.\n",
    "\n",
    "Contexto:\n",
    "{state['context']}\n",
    "\n",
    "Pregunta: {state['question']}\n",
    "\n",
    "Respuesta:\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"response\": response.content}\n",
    "\n",
    "def check_quality(state: AgenticRAGState) -> AgenticRAGState:\n",
    "    \"\"\"Check response quality.\"\"\"\n",
    "    prompt = f\"\"\"EvalÃºa la calidad de esta respuesta.\n",
    "    \n",
    "Pregunta: {state['question']}\n",
    "Contexto usado: {state['context']}\n",
    "Respuesta: {state['response']}\n",
    "\n",
    "Â¿La respuesta es BUENA, MEJORABLE o MALA?\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    quality = \"BUENA\" if \"BUENA\" in response.content.upper() else \"MEJORABLE\"\n",
    "    return {**state, \"response_quality\": quality, \"iteration\": state.get(\"iteration\", 0) + 1}\n",
    "\n",
    "def improve_response(state: AgenticRAGState) -> AgenticRAGState:\n",
    "    \"\"\"Improve the response.\"\"\"\n",
    "    prompt = f\"\"\"Mejora esta respuesta haciÃ©ndola mÃ¡s clara y completa.\n",
    "    \n",
    "Contexto: {state['context']}\n",
    "Respuesta original: {state['response']}\n",
    "\n",
    "Respuesta mejorada:\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return {**state, \"response\": response.content}\n",
    "\n",
    "def finalize(state: AgenticRAGState) -> AgenticRAGState:\n",
    "    \"\"\"Finalize the response.\"\"\"\n",
    "    return {**state, \"final_response\": state[\"response\"]}\n",
    "\n",
    "def no_info_response(state: AgenticRAGState) -> AgenticRAGState:\n",
    "    \"\"\"Response when no info found.\"\"\"\n",
    "    return {**state, \"final_response\": \"Lo siento, no tengo informaciÃ³n suficiente para responder a esa pregunta.\"}\n",
    "\n",
    "# Routing functions\n",
    "def route_context(state: AgenticRAGState) -> Literal[\"generate\", \"no_info\"]:\n",
    "    return \"generate\" if state[\"context_sufficient\"] else \"no_info\"\n",
    "\n",
    "def route_quality(state: AgenticRAGState) -> Literal[\"improve\", \"finalize\"]:\n",
    "    if state[\"response_quality\"] != \"BUENA\" and state.get(\"iteration\", 0) < 2:\n",
    "        return \"improve\"\n",
    "    return \"finalize\"\n",
    "\n",
    "print(\"Funciones de nodo definidas âœ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic RAG compilado âœ“\n"
     ]
    }
   ],
   "source": [
    "# Build the graph\n",
    "workflow = StateGraph(AgenticRAGState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"classify\", classify_question)\n",
    "workflow.add_node(\"reformulate\", reformulate_question)\n",
    "workflow.add_node(\"retrieve\", retrieve_context)\n",
    "workflow.add_node(\"check_context\", check_context)\n",
    "workflow.add_node(\"generate\", generate_response)\n",
    "workflow.add_node(\"check_quality\", check_quality)\n",
    "workflow.add_node(\"improve\", improve_response)\n",
    "workflow.add_node(\"finalize\", finalize)\n",
    "workflow.add_node(\"no_info\", no_info_response)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"classify\")\n",
    "workflow.add_edge(\"classify\", \"reformulate\")\n",
    "workflow.add_edge(\"reformulate\", \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"check_context\")\n",
    "workflow.add_conditional_edges(\"check_context\", route_context, \n",
    "                                {\"generate\": \"generate\", \"no_info\": \"no_info\"})\n",
    "workflow.add_edge(\"generate\", \"check_quality\")\n",
    "workflow.add_conditional_edges(\"check_quality\", route_quality,\n",
    "                                {\"improve\": \"improve\", \"finalize\": \"finalize\"})\n",
    "workflow.add_edge(\"improve\", \"check_quality\")\n",
    "workflow.add_edge(\"finalize\", END)\n",
    "workflow.add_edge(\"no_info\", END)\n",
    "\n",
    "# Compile with memory\n",
    "memory = MemorySaver()\n",
    "agentic_rag = workflow.compile(checkpointer=memory)\n",
    "\n",
    "print(\"Agentic RAG compilado âœ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Pregunta: Â¿QuÃ© bonificaciones hay para vehÃ­culos elÃ©ctricos?\n",
      "ğŸ·ï¸ Tipo: BONUS\n",
      "ğŸ”„ Reformulada: Pregunta reformulada: Â¿CuÃ¡les son las bonificaciones y subsidios gubernamentales actuales para la compra y uso de vehÃ­culos elÃ©ctricos en mi paÃ­s o regiÃ³n?\n",
      "âœ… Contexto suficiente: True\n",
      "â­ Calidad: BUENA\n",
      "ğŸ”¢ Iteraciones: 1\n",
      "\n",
      "ğŸ’¬ Respuesta final:\n",
      "Hay una bonificaciÃ³n del 75% para vehÃ­culos elÃ©ctricos en el IVTM.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Â¿QuÃ© bonificaciones hay para vehÃ­culos elÃ©ctricos?',\n",
       " 'question_type': 'BONUS',\n",
       " 'reformulated_question': 'Pregunta reformulada: Â¿CuÃ¡les son las bonificaciones y subsidios gubernamentales actuales para la compra y uso de vehÃ­culos elÃ©ctricos en mi paÃ­s o regiÃ³n?',\n",
       " 'context': '- Bonificaciones IVTM: vehÃ­culos elÃ©ctricos 75%, histÃ³ricos 100%.\\n- El IVTM grava la titularidad de vehÃ­culos. Se paga mientras estÃ© matriculado.\\n- El IBI se paga anualmente y grava bienes inmuebles urbanos y rÃºsticos.',\n",
       " 'context_sufficient': True,\n",
       " 'response': 'Hay una bonificaciÃ³n del 75% para vehÃ­culos elÃ©ctricos en el IVTM.',\n",
       " 'response_quality': 'BUENA',\n",
       " 'final_response': 'Hay una bonificaciÃ³n del 75% para vehÃ­culos elÃ©ctricos en el IVTM.',\n",
       " 'iteration': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the system\n",
    "def ask(question: str, session_id: str = \"default\"):\n",
    "    config = {\"configurable\": {\"thread_id\": session_id}}\n",
    "    result = agentic_rag.invoke({\n",
    "        \"question\": question,\n",
    "        \"question_type\": \"\",\n",
    "        \"reformulated_question\": \"\",\n",
    "        \"context\": \"\",\n",
    "        \"context_sufficient\": False,\n",
    "        \"response\": \"\",\n",
    "        \"response_quality\": \"\",\n",
    "        \"final_response\": \"\",\n",
    "        \"iteration\": 0\n",
    "    }, config=config)\n",
    "    \n",
    "    print(f\"\\nğŸ“ Pregunta: {question}\")\n",
    "    print(f\"ğŸ·ï¸ Tipo: {result['question_type']}\")\n",
    "    print(f\"ğŸ”„ Reformulada: {result['reformulated_question']}\")\n",
    "    print(f\"âœ… Contexto suficiente: {result['context_sufficient']}\")\n",
    "    print(f\"â­ Calidad: {result['response_quality']}\")\n",
    "    print(f\"ğŸ”¢ Iteraciones: {result['iteration']}\")\n",
    "    print(f\"\\nğŸ’¬ Respuesta final:\\n{result['final_response']}\")\n",
    "    return result\n",
    "\n",
    "# Test\n",
    "ask(\"Â¿QuÃ© bonificaciones hay para vehÃ­culos elÃ©ctricos?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Pregunta: Â¿CuÃ¡ndo se paga el IBI?\n",
      "ğŸ·ï¸ Tipo: DEADLINE\n",
      "ğŸ”„ Reformulada: Pregunta reformulada: Â¿CuÃ¡l es el plazo y la fecha lÃ­mite para el pago del Impuesto sobre Bienes Inmuebles (IBI) en EspaÃ±a?\n",
      "âœ… Contexto suficiente: True\n",
      "â­ Calidad: BUENA\n",
      "ğŸ”¢ Iteraciones: 1\n",
      "\n",
      "ğŸ’¬ Respuesta final:\n",
      "SegÃºn el contexto proporcionado, el IBI se paga anualmente, especÃ­ficamente en el segundo semestre.\n",
      "\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Pregunta: Â¿Puedo recurrir una liquidaciÃ³n?\n",
      "ğŸ·ï¸ Tipo: APPEAL\n",
      "ğŸ”„ Reformulada: Pregunta reformulada: Â¿CuÃ¡les son los pasos y requisitos legales para recurrir una liquidaciÃ³n de una empresa o una sentencia de liquidaciÃ³n en un tribunal?\n",
      "âœ… Contexto suficiente: True\n",
      "â­ Calidad: BUENA\n",
      "ğŸ”¢ Iteraciones: 1\n",
      "\n",
      "ğŸ’¬ Respuesta final:\n",
      "SÃ­, puedes recurrir una liquidaciÃ³n. Tienes 30 dÃ­as desde la notificaciÃ³n para interponer el recurso.\n",
      "\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Pregunta: Â¿QuÃ© descuentos hay para familias numerosas?\n",
      "ğŸ·ï¸ Tipo: OTHER\n",
      "ğŸ”„ Reformulada: Pregunta reformulada: Â¿CuÃ¡les son los beneficios y descuentos fiscales o de servicios pÃºblicos disponibles para familias numerosas en mi paÃ­s o regiÃ³n?\n",
      "âœ… Contexto suficiente: True\n",
      "â­ Calidad: BUENA\n",
      "ğŸ”¢ Iteraciones: 1\n",
      "\n",
      "ğŸ’¬ Respuesta final:\n",
      "Hasta un 90% en el Impuesto de Bienes Inmuebles (IBI).\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test more questions\n",
    "questions = [\n",
    "    \"Â¿CuÃ¡ndo se paga el IBI?\",\n",
    "    \"Â¿Puedo recurrir una liquidaciÃ³n?\",\n",
    "    \"Â¿QuÃ© descuentos hay para familias numerosas?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    ask(q)\n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"evaluacion\"></a>\n",
    "## 4. EvaluaciÃ³n con mÃ©tricas\n",
    "\n",
    "Evaluamos la calidad del sistema RAG con mÃ©tricas clave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Pregunta: Â¿QuÃ© es el IBI?\n",
      "ğŸ·ï¸ Tipo: DEFINITION\n",
      "ğŸ”„ Reformulada: Pregunta reformulada: Â¿QuÃ© es el Impuesto sobre Bienes Inmuebles (IBI) y cÃ³mo se calcula en EspaÃ±a?\n",
      "âœ… Contexto suficiente: True\n",
      "â­ Calidad: BUENA\n",
      "ğŸ”¢ Iteraciones: 1\n",
      "\n",
      "ğŸ’¬ Respuesta final:\n",
      "El IBI (Impuesto de Bienes Inmuebles) es un impuesto que se paga anualmente y grava bienes inmuebles urbanos y rÃºsticos.\n",
      "\n",
      "ğŸ“Š EvaluaciÃ³n:\n",
      "Fidelidad: La puntuaciÃ³n serÃ­a 1, ya que la respuesta estÃ¡ completamente basada en el contexto proporcionado. La oraciÃ³n \"El IBI se paga anualmente y grava bienes inmuebles urbanos y rÃºsticos\" se encuentra directamente en el contexto, lo que indica que la respuesta es una reproducciÃ³n exacta de la informaciÃ³n proporcionada.\n",
      "Relevancia: La respuesta es completamente relevante para la pregunta, ya que define claramente quÃ© es el IBI y a quÃ© se aplica. Por lo tanto, le darÃ­a una puntuaciÃ³n de 1.\n"
     ]
    }
   ],
   "source": [
    "# Simple evaluation without RAGAS (to avoid dependency issues)\n",
    "def evaluate_response(question, response, context, ground_truth=None):\n",
    "    \"\"\"Simple evaluation of RAG response quality.\"\"\"\n",
    "    \n",
    "    # Check if response is grounded in context (faithfulness)\n",
    "    faithfulness_prompt = f\"\"\"Â¿La respuesta estÃ¡ basada en el contexto proporcionado?\n",
    "    \n",
    "Contexto: {context}\n",
    "Respuesta: {response}\n",
    "\n",
    "PuntÃºa de 0 a 1 (donde 1 es completamente basada en el contexto).\"\"\"\n",
    "    \n",
    "    faith_score = llm.invoke(faithfulness_prompt)\n",
    "    \n",
    "    # Check relevance\n",
    "    relevance_prompt = f\"\"\"Â¿La respuesta es relevante para la pregunta?\n",
    "    \n",
    "Pregunta: {question}\n",
    "Respuesta: {response}\n",
    "\n",
    "PuntÃºa de 0 a 1.\"\"\"\n",
    "    \n",
    "    rel_score = llm.invoke(relevance_prompt)\n",
    "    \n",
    "    return {\n",
    "        \"faithfulness_eval\": faith_score.content,\n",
    "        \"relevance_eval\": rel_score.content\n",
    "    }\n",
    "\n",
    "# Evaluate one response\n",
    "test_result = ask(\"Â¿QuÃ© es el IBI?\")\n",
    "eval_result = evaluate_response(\n",
    "    test_result[\"question\"],\n",
    "    test_result[\"final_response\"],\n",
    "    test_result[\"context\"]\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Š EvaluaciÃ³n:\")\n",
    "print(f\"Fidelidad: {eval_result['faithfulness_eval']}\")\n",
    "print(f\"Relevancia: {eval_result['relevance_eval']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"produccion\"></a>\n",
    "## 5. Mejores prÃ¡cticas de producciÃ³n\n",
    "\n",
    "### Checklist para producciÃ³n\n",
    "\n",
    "- [ ] **Logging**: Registrar todas las consultas y respuestas\n",
    "- [ ] **MÃ©tricas**: Monitorear latencia, calidad, uso\n",
    "- [ ] **Rate limiting**: Controlar costos de API\n",
    "- [ ] **Fallbacks**: Respuestas por defecto si falla\n",
    "- [ ] **Caching**: Cachear respuestas frecuentes\n",
    "- [ ] **Testing**: Tests automatizados de regresiÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AgenticRAG:Query received: Â¿CuÃ¡les son los plazos de pago?\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 2.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 2.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:AgenticRAG:Response generated in 5.04s\n",
      "INFO:AgenticRAG:Quality: BUENA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Pregunta: Â¿CuÃ¡les son los plazos de pago?\n",
      "ğŸ·ï¸ Tipo: DEADLINE\n",
      "ğŸ”„ Reformulada: Pregunta reformulada: Â¿CuÃ¡les son los plazos y condiciones especÃ­ficas de pago que se aplican a este servicio o producto?\n",
      "âœ… Contexto suficiente: True\n",
      "â­ Calidad: BUENA\n",
      "ğŸ”¢ Iteraciones: 1\n",
      "\n",
      "ğŸ’¬ Respuesta final:\n",
      "Los plazos de pago son:\n",
      "- IBI: segundo semestre\n",
      "- IVTM: primer trimestre\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Â¿CuÃ¡les son los plazos de pago?',\n",
       " 'question_type': 'DEADLINE',\n",
       " 'reformulated_question': 'Pregunta reformulada: Â¿CuÃ¡les son los plazos y condiciones especÃ­ficas de pago que se aplican a este servicio o producto?',\n",
       " 'context': '- El IVTM grava la titularidad de vehÃ­culos. Se paga mientras estÃ© matriculado.\\n- Plazos de pago: IBI segundo semestre, IVTM primer trimestre.\\n- Recursos: Puede interponer recurso en 30 dÃ­as desde la notificaciÃ³n.',\n",
       " 'context_sufficient': True,\n",
       " 'response': 'Los plazos de pago son:\\n- IBI: segundo semestre\\n- IVTM: primer trimestre',\n",
       " 'response_quality': 'BUENA',\n",
       " 'final_response': 'Los plazos de pago son:\\n- IBI: segundo semestre\\n- IVTM: primer trimestre',\n",
       " 'iteration': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Add logging wrapper\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"AgenticRAG\")\n",
    "\n",
    "def ask_with_logging(question: str, session_id: str = \"default\"):\n",
    "    \"\"\"Wrapper with logging for production.\"\"\"\n",
    "    start_time = datetime.now()\n",
    "    logger.info(f\"Query received: {question}\")\n",
    "    \n",
    "    try:\n",
    "        result = ask(question, session_id)\n",
    "        \n",
    "        elapsed = (datetime.now() - start_time).total_seconds()\n",
    "        logger.info(f\"Response generated in {elapsed:.2f}s\")\n",
    "        logger.info(f\"Quality: {result['response_quality']}\")\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing query: {e}\")\n",
    "        return {\"final_response\": \"Lo siento, ocurriÃ³ un error. Intenta de nuevo.\"}\n",
    "\n",
    "# Test\n",
    "ask_with_logging(\"Â¿CuÃ¡les son los plazos de pago?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ejercicio\"></a>\n",
    "## 6. Ejercicio Final\n",
    "\n",
    "### Mejora el sistema Agentic RAG\n",
    "\n",
    "AÃ±ade las siguientes mejoras:\n",
    "1. CitaciÃ³n de fuentes en la respuesta\n",
    "2. DetecciÃ³n de idioma\n",
    "3. Historial de conversaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Implement improvements\n",
    "# 1. Modify generate_response to include source citations\n",
    "# 2. Add a language detection node\n",
    "# 3. Implement conversation history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "En este notebook hemos construido un sistema **Agentic RAG** completo:\n",
    "\n",
    "1. **ClasificaciÃ³n** de preguntas\n",
    "2. **ReformulaciÃ³n** para mejor retrieval\n",
    "3. **VerificaciÃ³n** de contexto suficiente\n",
    "4. **GeneraciÃ³n** de respuestas\n",
    "5. **Auto-correcciÃ³n** iterativa\n",
    "6. **EvaluaciÃ³n** de calidad\n",
    "\n",
    "Este patrÃ³n es la base para asistentes de IA en producciÃ³n.\n",
    "\n",
    "En el siguiente y Ãºltimo notebook veremos **Modelos de Gran Contexto y Multimodales**.\n",
    "\n",
    "---\n",
    "\n",
    "## Referencias\n",
    "\n",
    "- [LangGraph Agentic RAG](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/)\n",
    "- [RAGAS Evaluation](https://docs.ragas.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "ipykernel                   7.2.0\n",
      "langchain_community         0.4.1\n",
      "langchain_core              1.2.9\n",
      "langchain_groq              1.1.2\n",
      "langchain_huggingface       NA\n",
      "langgraph                   NA\n",
      "session_info                v1.0.1\n",
      "-----\n",
      "IPython             9.10.0\n",
      "jupyter_client      8.8.0\n",
      "jupyter_core        5.9.1\n",
      "-----\n",
      "Python 3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]\n",
      "Windows-11-10.0.26200-SP0\n",
      "-----\n",
      "Session information updated at 2026-02-10 07:09\n"
     ]
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show(html=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA_LLM",
   "language": "python",
   "name": "ia_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
